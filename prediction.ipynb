{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deployment_model.seq_model import SeqModel\n",
    "from preprocessing_helper import *\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext.data import Field, Pipeline\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.pipeline.Pipeline at 0x7f8fdd262210>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_pipeline = Pipeline(lemmatize)\n",
    "pre_pipeline.add()\n",
    "pre_pipeline.add_before(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = Field(sequential=True, tokenize=word_tokenize, lower=True, preprocessing=pre_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['neu', 'neg', 'pos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "with open(\"vocab.pkl\", \"rb\") as f:\n",
    "    vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'm', 'very', 'excite', 'about', 'this', 'amaze', 'event']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.preprocess(\"I'm very exciting about this amazing event\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {\n",
    "    \"hidden_size\": 302,\n",
    "    \"lr\": 0.00010769630091763721,\n",
    "    \"l2\": 2.5888680371842294e-05,\n",
    "    \"nonlin\": \"tanh\",\n",
    "    \"dropout\": 0.1,\n",
    "    \"num_layers\": 2,\n",
    "    \"mode\": 0,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"momentum\": 0.1,\n",
    "}\n",
    "\n",
    "best_model = SeqModel(\n",
    "    embedding_size=100,\n",
    "    vocab_size=len(vocab),\n",
    "    output_size=3,\n",
    "    hidden_size=best_config[\"hidden_size\"],\n",
    "    num_layers=best_config[\"num_layers\"],\n",
    "    nonlin=best_config[\"nonlin\"],\n",
    "    dropout_rate=best_config[\"dropout\"],\n",
    "    mode=best_config[\"mode\"],\n",
    "    unit=\"gru\",\n",
    "    more_features=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.load_state_dict(torch.load(\"model_deploy.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'be', 'not', 'happy', 'at', 'all']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 498, 0, 0]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_input = \"I am not happy at all\"\n",
    "print(TEXT.preprocess(new_input))\n",
    "trans_input = [vocab.get(token, 0) for token in TEXT.preprocess(new_input)]\n",
    "trans_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1397, -2.0872, -0.5869]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_outputs = best_model(torch.LongTensor(trans_input).reshape((-1,1)))\n",
    "model_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities, predicted = torch.max(model_outputs.cpu().data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label = LABELS[predicted]\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
