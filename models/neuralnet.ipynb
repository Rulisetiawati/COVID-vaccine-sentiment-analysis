{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neuralnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWgu1YY7Hs_Q",
        "outputId": "e1e4c677-3c92-4381-8e96-d03a0d200959"
      },
      "source": [
        "!pip install catboost\n",
        "!pip install emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting catboost\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/37/bc4e0ddc30c07a96482abf1de7ed1ca54e59bba2026a33bca6d2ef286e5b/catboost-0.24.4-cp36-none-manylinux1_x86_64.whl (65.7MB)\n",
            "\u001b[K     |████████████████████████████████| 65.8MB 64kB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-0.24.4\n",
            "Collecting emoji\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/fa/b3368f41b95a286f8d300e323449ab4e86b85334c2e0b477e94422b8ed0f/emoji-1.2.0-py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 7.6MB/s \n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMVLJxsKHuY2",
        "outputId": "59945394-80fe-4fb4-8425-21af08249d50"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYauhgoEHwAs"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/sent-analysis\")\n",
        "from feature_extractions_helper import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y2xZoIMHomr",
        "outputId": "f5328fd9-4992-4b90-cd4b-4f61ca056a85"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "import nltk\n",
        "import numpy as np\n",
        "import torchtext\n",
        "import scipy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
        "from sklearn.model_selection import (\n",
        "    GridSearchCV,\n",
        "    RandomizedSearchCV,\n",
        "    cross_val_score,\n",
        "    cross_validate,\n",
        "    train_test_split,\n",
        ")\n",
        "from sklearn.impute import SimpleImputer\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, f1_score, make_scorer\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm.sklearn import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from scipy.stats import lognorm, loguniform, randint\n",
        "from collections import Counter\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import optim\n",
        "from torchtext.data import Field, LabelField\n",
        "from torchtext.data import TabularDataset\n",
        "from torchtext.data import Iterator, BucketIterator\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK4aN99GHzAo"
      },
      "source": [
        "df = pd.read_csv(\"../data/processed/processed_data_7760.csv\", index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QOhZgfAH1Yp"
      },
      "source": [
        "train_df, validation_df = train_test_split(df, test_size = 0.3, random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D4RZOPmHVjk"
      },
      "source": [
        "val_df, test_df = train_test_split(validation_df, test_size=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wAcHrDqHoIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c70c88a-a83a-4e82-8bdb-d70875d06173"
      },
      "source": [
        "print(train_df.shape)\n",
        "print(val_df.shape)\n",
        "print(test_df.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5432, 33)\n",
            "(1164, 33)\n",
            "(1164, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJg1y09iL8y6"
      },
      "source": [
        "drop_features = [\"created_at\", \"id\", \"entities\", \"is_quote_status\", \"location\", \"tags_count\"] # I'll add tags_counts later\n",
        "target = \"sentiment\"\n",
        "categorical_features = [\"keyword\", \"city\", \"province\", \"country\"]\n",
        "text_feature = \"processed_text\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfAQ8SODL-O2",
        "outputId": "193c18c5-8f4f-435e-b6bb-9221ae50c535"
      },
      "source": [
        "numeric_list = train_df.select_dtypes(include=np.number).columns.tolist()\n",
        "numeric_set = set(numeric_list) - {\"id\"}\n",
        "# numeric_set.add(\"possibly_sensitive\") # numeric feature\n",
        "numeric_features = list(numeric_set)\n",
        "numeric_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cap_words_count',\n",
              " 'avg_pos_words',\n",
              " 'second_person_pron_count',\n",
              " 'avg_neg_words',\n",
              " 'retweet_count',\n",
              " 'hashtags_count',\n",
              " 'avg_slang_sent',\n",
              " 'avg_len_sent',\n",
              " 'third_person_pron_count',\n",
              " 'coord_conj_count',\n",
              " 'favorite_count',\n",
              " 'future_tense_count',\n",
              " 'multi_punc_count',\n",
              " 'commas_count',\n",
              " 'first_preson_pron_count',\n",
              " 'sentence_count',\n",
              " 'slang_acronym_count',\n",
              " 'past_tense_count',\n",
              " 'avg_len_tokens']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3vIC3zDZDS1",
        "outputId": "75377cf9-c100-4dcf-89af-00e11e28abda"
      },
      "source": [
        "keep_columns = [\"sentiment\", \"processed_text\"] + numeric_features\n",
        "keep_columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sentiment',\n",
              " 'processed_text',\n",
              " 'cap_words_count',\n",
              " 'avg_pos_words',\n",
              " 'second_person_pron_count',\n",
              " 'avg_neg_words',\n",
              " 'retweet_count',\n",
              " 'hashtags_count',\n",
              " 'avg_slang_sent',\n",
              " 'avg_len_sent',\n",
              " 'third_person_pron_count',\n",
              " 'coord_conj_count',\n",
              " 'favorite_count',\n",
              " 'future_tense_count',\n",
              " 'multi_punc_count',\n",
              " 'commas_count',\n",
              " 'first_preson_pron_count',\n",
              " 'sentence_count',\n",
              " 'slang_acronym_count',\n",
              " 'past_tense_count',\n",
              " 'avg_len_tokens']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhBUEF1eH_27"
      },
      "source": [
        "import os\n",
        "save_path = \"../data/split/\"\n",
        "if not os.path.exists(save_path):\n",
        "    os.mkdir(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTrwjg7pIAVv"
      },
      "source": [
        "train_df[keep_columns].to_csv(\"../data/split/train.tsv\", sep='\\t', index=False)\n",
        "val_df[keep_columns].to_csv(\"../data/split/val.tsv\", sep='\\t', index=False)\n",
        "test_df[keep_columns].to_csv(\"../data/split/test.tsv\", sep='\\t', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhOHCwJBIEAq"
      },
      "source": [
        "train_df = pd.read_csv(\"../data/split/train.tsv\", delimiter=\"\\t\")\n",
        "val_df = pd.read_csv(\"../data/split/val.tsv\", delimiter=\"\\t\")\n",
        "test_df = pd.read_csv(\"../data/split/test.tsv\", delimiter=\"\\t\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUsaHdR5IFKl"
      },
      "source": [
        "TEXT = Field(sequential=True, tokenize=word_tokenize, lower=True, stop_words=STOPWORDS)\n",
        "NUM_FEATS = Field(sequential=False, use_vocab=False, unk_token=False, dtype=torch.float)\n",
        "LABEL = Field(sequential=False, unk_token=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYqQmWpHIGbe"
      },
      "source": [
        "train_set, val_set, test_set = TabularDataset.splits(path=\"../data/split/\",\n",
        "                                         train=\"train.tsv\", validation=\"val.tsv\", test=\"test.tsv\",\n",
        "                                         format=\"tsv\",\n",
        "                                         skip_header=True,\n",
        "                                         fields=[('label', LABEL),\n",
        "                                                 (\"content\", TEXT),\n",
        "                                                 ('favorite_count', NUM_FEATS),\n",
        "                                                 ('third_person_pron_count', NUM_FEATS),\n",
        "                                                 ('past_tense_count', NUM_FEATS),\n",
        "                                                 ('retweet_count', NUM_FEATS),\n",
        "                                                 ('commas_count', NUM_FEATS),\n",
        "                                                 ('avg_slang_sent', NUM_FEATS),\n",
        "                                                 ('coord_conj_count', NUM_FEATS),\n",
        "                                                 ('future_tense_count', NUM_FEATS),\n",
        "                                                 ('multi_punc_count', NUM_FEATS),\n",
        "                                                 ('second_person_pron_count', NUM_FEATS),\n",
        "                                                 ('hashtags_count', NUM_FEATS),\n",
        "                                                 ('slang_acronym_count', NUM_FEATS),\n",
        "                                                 ('cap_words_count', NUM_FEATS),\n",
        "                                                 ('avg_len_sent', NUM_FEATS),\n",
        "                                                 ('first_preson_pron_count', NUM_FEATS),\n",
        "                                                 ('sentence_count', NUM_FEATS),\n",
        "                                                 ('avg_neg_words', NUM_FEATS),\n",
        "                                                 ('avg_pos_words', NUM_FEATS),\n",
        "                                                 ('avg_len_tokens', NUM_FEATS),\n",
        "                                                 ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mL6dG6egcDCY",
        "outputId": "4211c828-6922-4a94-bbd9-4d65e7d8c432"
      },
      "source": [
        "train_set.fields"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'avg_len_sent': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'avg_len_tokens': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'avg_neg_words': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'avg_pos_words': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'avg_slang_sent': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'cap_words_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'commas_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'content': <torchtext.data.field.Field at 0x7f60793ec7f0>,\n",
              " 'coord_conj_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'favorite_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'first_preson_pron_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'future_tense_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'hashtags_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'label': <torchtext.data.field.Field at 0x7f60793eca20>,\n",
              " 'multi_punc_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'past_tense_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'retweet_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'second_person_pron_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'sentence_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'slang_acronym_count': <torchtext.data.field.Field at 0x7f60793ec860>,\n",
              " 'third_person_pron_count': <torchtext.data.field.Field at 0x7f60793ec860>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q_mYJJlIHq-"
      },
      "source": [
        "TEXT.build_vocab(train_set, min_freq=2, vectors=torchtext.vocab.Vectors(name=\"./glove.twitter.27B/glove.twitter.27B.100d.txt\"))\n",
        "LABEL.build_vocab(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFFReC8VII8l"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD8Gv3TuIKQR"
      },
      "source": [
        "train_iter, val_iter = BucketIterator.splits(\n",
        "    (train_set, val_set),\n",
        "    batch_sizes=(32,32),\n",
        "    sort_key=lambda x: len(x.content), \n",
        "    sort=True,\n",
        "    sort_within_batch=True,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "test_iter = Iterator(\n",
        "    dataset = test_set, # we pass in the datasets we want the iterator to draw data from\n",
        "    sort = False, # don't sort the examples\n",
        "    batch_size=32, # batch size\n",
        "    sort_key=None, # no sorting\n",
        "    shuffle=False, # don't shuffle the examples\n",
        "    sort_within_batch=False, # no sorting\n",
        "    device=device, # cpu vs cuda\n",
        "    train=False # this is not a train set\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1brFEsXILoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18bccd51-e695-41d7-e9bd-3cc9c450a80d"
      },
      "source": [
        "for batch in train_iter:\n",
        "    print(batch.content)\n",
        "    print(batch.content.shape)\n",
        "    print(batch.label.shape)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[  60,   73,    4,   64,  104,    0,  243, 2269, 1284,    3,  239,    8,\n",
            "            6,    2, 3596, 2282,    0,  274, 2412, 2403, 1472,    6,    8,  386,\n",
            "          700,  700,  619,    8,  856, 3236, 1778,   30],\n",
            "        [ 880,    2,    2,   73, 1812,    0,    3, 1315,    2,    0,  164,    2,\n",
            "          559,    0,    0,    6,    0,  266,    6,    2,    8,   75,    0,   88,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1],\n",
            "        [2151,   30,    0,    2,    6,    0,    2,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "            1,    1,    1,    1,    1,    1,    1,    1]])\n",
            "torch.Size([3, 32])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMBw-s04INl1"
      },
      "source": [
        "VOCAB_SIZE = len(TEXT.vocab.stoi)\n",
        "EMBEDDING_SIZE = TEXT.vocab.vectors.shape[1]\n",
        "NUM_CLASSES = 3\n",
        "MAX_EPOCHS = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLGVkjgArlOi"
      },
      "source": [
        "glove = TEXT.vocab.vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Ls3KSEIR9w"
      },
      "source": [
        "import pdb\n",
        "class SeqModel(nn.Module):\n",
        "  \n",
        "  def __init__(self, embedding_size=200, vocab_size=300, output_size=5, hidden_size=200, \n",
        "               num_layers=2, nonlin=\"tanh\", dropout_rate=0.7, mode=0, unit=\"lstm\", more_features=False):\n",
        "              # add glove param here? ^^\n",
        "\n",
        "    super(SeqModel, self).__init__()\n",
        "    self.mode = mode\n",
        "    self.unit = unit\n",
        "    self.more_features = more_features\n",
        "\n",
        "    self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size).from_pretrained(glove, freeze=True)\n",
        "    # self.embedding.weight.data.normal_(0.0,0.05) # mean=0.0, mu=0.05\n",
        "\n",
        "    \n",
        "    if mode == 0:\n",
        "        if unit == \"lstm\":\n",
        "            self.lstm_rnn = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers)\n",
        "        elif unit == \"gru\":\n",
        "            self.gru_rnn = nn.GRU(input_size=embedding_size ,hidden_size=hidden_size, num_layers=num_layers)\n",
        "        else:\n",
        "            #baseline: unidirectional rnn\n",
        "            self.rnn = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, nonlinearity=nonlin)\n",
        "        if more_features:\n",
        "            self.linear_layer = nn.Linear(hidden_size + len(numeric_features), output_size)\n",
        "        else:\n",
        "            self.linear_layer = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    #model with dropout:\n",
        "    if mode == 1:\n",
        "        if unit == \"lstm\":\n",
        "            self.lstm_rnn = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout_rate, )\n",
        "        elif unit == \"gru\":\n",
        "            self.gru_rnn = nn.GRU(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout_rate)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, nonlinearity=nonlin, dropout=dropout_rate)\n",
        "\n",
        "        if more_features:\n",
        "            self.linear_layer = nn.Linear(hidden_size + len(numeric_features), output_size)\n",
        "        else:\n",
        "            self.linear_layer = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    #Bidirectional model\n",
        "    if mode == 2:\n",
        "        if unit == \"lstm\":\n",
        "            self.lstm_rnn = nn.LSTM(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout_rate, bidirectional=True)\n",
        "        elif unit == \"gru\":\n",
        "            self.gru_rnn = nn.GRU(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout_rate, bidirectional=True)\n",
        "        else:\n",
        "            self.rnn = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, nonlinearity=nonlin, dropout=dropout_rate, bidirectional=True)\n",
        "\n",
        "        if more_features:\n",
        "            self.linear_layer = nn.Linear(hidden_size * 2 + len(numeric_features), output_size)\n",
        "        else:\n",
        "            self.linear_layer = nn.Linear(hidden_size * 2, output_size)\n",
        "\n",
        "    self.activation_fn = nonlin\n",
        "    self.softmax_layer = nn.LogSoftmax(dim=1)\n",
        "  \n",
        "  def forward(self, x, x_concat=None):\n",
        "      #permute x?\n",
        "      out = self.embedding(x)\n",
        "      if self.unit == \"lstm\":\n",
        "          out, (h_state, c_state) = self.lstm_rnn(out)\n",
        "      elif self.unit == \"gru\":\n",
        "          out, h_state = self.gru_rnn(out)\n",
        "      else:\n",
        "          out, h_state = self.rnn(out)\n",
        "      out = out[-1]\n",
        "      if self.more_features:\n",
        "        out = torch.cat((out, x_concat.permute(1,0)), dim=1)\n",
        "      out = self.linear_layer(out)\n",
        "      out = self.softmax_layer(out)\n",
        "      return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8oWD-VcITS7"
      },
      "source": [
        "# Attribution: UBC MDS-CL supervised learning II lab code from Peter Sullivan\n",
        "def train(loader, model, criterion, optimizer, device):\n",
        "    total_loss = 0.0\n",
        "    # iterate throught the data loader\n",
        "    num_sample = 0\n",
        "    for batch in loader:\n",
        "        # load the current batch\n",
        "        batch_input = batch.content\n",
        "        batch_output = batch.label\n",
        "        batch_numeric = torch.stack([batch.retweet_count,\n",
        "                         batch.coord_conj_count,\n",
        "                         batch.first_preson_pron_count,\n",
        "                         batch.commas_count,\n",
        "                         batch.slang_acronym_count,\n",
        "                         batch.avg_neg_words,\n",
        "                         batch.avg_len_sent,\n",
        "                         batch.future_tense_count,\n",
        "                         batch.hashtags_count,\n",
        "                         batch.cap_words_count,\n",
        "                         batch.sentence_count,\n",
        "                         batch.avg_pos_words,\n",
        "                         batch.avg_len_tokens,\n",
        "                         batch.past_tense_count,\n",
        "                         batch.multi_punc_count,\n",
        "                         batch.avg_slang_sent,\n",
        "                         batch.third_person_pron_count,\n",
        "                         batch.favorite_count,\n",
        "                         batch.second_person_pron_count])\n",
        "        batch_input = batch_input.to(device)\n",
        "        batch_output = batch_output.to(device)\n",
        "        batch_numeric = batch_numeric.to(device)\n",
        "        # forward propagation\n",
        "        # pass the data through the model\n",
        "        model_outputs = model(batch_input, batch_numeric)\n",
        "        # compute the loss\n",
        "        cur_loss = criterion(model_outputs, batch_output)\n",
        "        total_loss += cur_loss.cpu().item()\n",
        "\n",
        "        # backward propagation (compute the gradients and update the model)\n",
        "        # clear the buffer\n",
        "        optimizer.zero_grad()\n",
        "        # compute the gradients\n",
        "        cur_loss.backward()\n",
        "        # update the weights\n",
        "        optimizer.step()\n",
        "\n",
        "        num_sample += batch_output.shape[0]\n",
        "\n",
        "    return total_loss/num_sample\n",
        "\n",
        "# evaluation logic based on classification accuracy\n",
        "def evaluate(loader, model, criterion, device):\n",
        "    all_pred=[]\n",
        "    all_label = []\n",
        "    with torch.no_grad(): # impacts the autograd engine and deactivate it. reduces memory usage and speeds up computation\n",
        "        for batch in loader:\n",
        "             # load the current batch\n",
        "            batch_input = batch.content\n",
        "            batch_output = batch.label\n",
        "            batch_numeric = torch.stack([batch.retweet_count,\n",
        "                  batch.coord_conj_count,\n",
        "                  batch.first_preson_pron_count,\n",
        "                  batch.commas_count,\n",
        "                  batch.slang_acronym_count,\n",
        "                  batch.avg_neg_words,\n",
        "                  batch.avg_len_sent,\n",
        "                  batch.future_tense_count,\n",
        "                  batch.hashtags_count,\n",
        "                  batch.cap_words_count,\n",
        "                  batch.sentence_count,\n",
        "                  batch.avg_pos_words,\n",
        "                  batch.avg_len_tokens,\n",
        "                  batch.past_tense_count,\n",
        "                  batch.multi_punc_count,\n",
        "                  batch.avg_slang_sent,\n",
        "                  batch.third_person_pron_count,\n",
        "                  batch.favorite_count,\n",
        "                  batch.second_person_pron_count])\n",
        "            \n",
        "            batch_input = batch_input.to(device)\n",
        "            batch_numeric = batch_numeric.to(device)\n",
        "            # forward propagation\n",
        "            # pass the data through the model\n",
        "            model_outputs = model(batch_input, batch_numeric)\n",
        "            # identify the predicted class for each example in the batch\n",
        "            probabilities, predicted = torch.max(model_outputs.cpu().data, 1)\n",
        "            # put all the true labels and predictions to two lists\n",
        "            all_pred.extend(predicted)\n",
        "            all_label.extend(batch_output.cpu())\n",
        "            \n",
        "    accuracy = accuracy_score(all_label, all_pred)\n",
        "    f1score = f1_score(all_label, all_pred, average='micro') \n",
        "    return accuracy, f1score"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysnkSKpbIUv4"
      },
      "source": [
        "# Attribution: UBC MDS-CL supervised learning II lab code from Peter Sullivan\n",
        "def random_search(num_iter, architecture):    \n",
        "    results = []\n",
        "    for i in range(num_iter):\n",
        "        #define hyperparameters here\n",
        "        config = {\n",
        "            \"hidden_size\": scipy.stats.randint.rvs(100,500),\n",
        "            \"lr\": scipy.stats.loguniform.rvs(10**-4,0.1),\n",
        "            \"l2\": scipy.stats.loguniform.rvs(10**-5,10**-2),\n",
        "            \"nonlin\" : np.random.choice([\"relu\",\"tanh\"]),\n",
        "            \"dropout\":np.random.choice(np.arange(0.1, 1, 0.1)),\n",
        "            \"num_layers\": np.random.choice([1,2]),\n",
        "            \"mode\": np.random.choice([0,1,2]),\n",
        "            \"optimizer\": np.random.choice([\"Adam\"]),\n",
        "            \"momentum\": np.random.choice(np.arange(0.1, 1, 0.1))\n",
        "        }\n",
        "\n",
        "        print(\"new config\")\n",
        "        print(config)\n",
        "        model = SeqModel(embedding_size=EMBEDDING_SIZE, \n",
        "                          vocab_size=VOCAB_SIZE, \n",
        "                          output_size=NUM_CLASSES, \n",
        "                          hidden_size=config[\"hidden_size\"], \n",
        "                          num_layers=config[\"num_layers\"], \n",
        "                          nonlin=config[\"nonlin\"],\n",
        "                          dropout_rate=config[\"dropout\"],\n",
        "                          mode=config[\"mode\"],\n",
        "                          unit=architecture,\n",
        "                          more_features=True)\n",
        "        \n",
        "        model = model.to(device)\n",
        "        criterion = nn.NLLLoss()\n",
        "        if config[\"optimizer\"] == \"Adam\":\n",
        "          optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"l2\"])\n",
        "        else:\n",
        "          optimizer = torch.optim.SGD(model.parameters(), lr=config[\"lr\"], weight_decay=config[\"l2\"], momentum=config[\"momentum\"])\n",
        "\n",
        "    \n",
        "        max_val = 0\n",
        "        best_epoch = 0\n",
        "        for epoch in range(MAX_EPOCHS):\n",
        "        # train the model for one pass over the data\n",
        "            train_loss = train(train_iter, model, criterion, optimizer, device)  \n",
        "        # compute the training accuracy\n",
        "            train_acc, train_f1 = evaluate(train_iter, model, criterion, device)\n",
        "        # compute the validation accuracy\n",
        "            vac_acc, val_f1 = evaluate(val_iter, model, criterion, device)\n",
        "            if val_f1 > max_val:\n",
        "                max_val = val_f1\n",
        "                best_epoch = epoch + 1\n",
        "                best_model = model\n",
        "        # print the loss for every epoch\n",
        "            print('Epoch [{}/{}], Loss: {:.4f}, Training F1-score: {:.4f}, Validation F1-score: {:.4f}'.format(epoch+1, MAX_EPOCHS, train_loss, train_f1, val_f1))\n",
        "        results.append((max_val,best_epoch,config))\n",
        "        print(\"Best validation score for iterations #{}: {}\".format(i,max_val))\n",
        "    return results, best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gf5FuUUnIWBq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84874135-bf29-4970-c688-155fea9347c9"
      },
      "source": [
        "units = [\"rnn\", \"gru\", \"lstm\"]\n",
        "for unit in units:\n",
        "    print(f\"************* Architecture: {unit} *************\")\n",
        "    random_search(20, unit)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "************* Architecture: rnn *************\n",
            "new config\n",
            "{'hidden_size': 476, 'lr': 0.01678726497584567, 'l2': 0.0005582090037501318, 'nonlin': 'tanh', 'dropout': 0.4, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.5}\n",
            "Epoch [1/10], Loss: 0.1570, Training F1-score: 0.5313, Validation F1-score: 0.5249\n",
            "Epoch [2/10], Loss: 0.3463, Training F1-score: 0.4608, Validation F1-score: 0.4553\n",
            "Epoch [3/10], Loss: 0.2238, Training F1-score: 0.5543, Validation F1-score: 0.5301\n",
            "Epoch [4/10], Loss: 0.3367, Training F1-score: 0.4753, Validation F1-score: 0.4691\n",
            "Epoch [5/10], Loss: 0.2109, Training F1-score: 0.5394, Validation F1-score: 0.5077\n",
            "Epoch [6/10], Loss: 0.3940, Training F1-score: 0.5747, Validation F1-score: 0.5404\n",
            "Epoch [7/10], Loss: 0.2223, Training F1-score: 0.6539, Validation F1-score: 0.6649\n",
            "Epoch [8/10], Loss: 0.2009, Training F1-score: 0.6272, Validation F1-score: 0.6392\n",
            "Epoch [9/10], Loss: 0.2388, Training F1-score: 0.6484, Validation F1-score: 0.6598\n",
            "Epoch [10/10], Loss: 0.2340, Training F1-score: 0.6727, Validation F1-score: 0.6796\n",
            "Best validation score for iterations #0: 0.679553264604811\n",
            "new config\n",
            "{'hidden_size': 153, 'lr': 0.0007019857830434542, 'l2': 3.776825258672385e-05, 'nonlin': 'relu', 'dropout': 0.6, 'num_layers': 1, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.6}\n",
            "Epoch [1/10], Loss: 0.0439, Training F1-score: 0.6946, Validation F1-score: 0.6976\n",
            "Epoch [2/10], Loss: 0.0367, Training F1-score: 0.7526, Validation F1-score: 0.7552\n",
            "Epoch [3/10], Loss: 0.0323, Training F1-score: 0.7281, Validation F1-score: 0.7277\n",
            "Epoch [4/10], Loss: 0.0295, Training F1-score: 0.7682, Validation F1-score: 0.7672\n",
            "Epoch [5/10], Loss: 0.0285, Training F1-score: 0.7616, Validation F1-score: 0.7552\n",
            "Epoch [6/10], Loss: 0.0245, Training F1-score: 0.7730, Validation F1-score: 0.7586\n",
            "Epoch [7/10], Loss: 0.0237, Training F1-score: 0.8115, Validation F1-score: 0.7655\n",
            "Epoch [8/10], Loss: 0.0250, Training F1-score: 0.8176, Validation F1-score: 0.7620\n",
            "Epoch [9/10], Loss: 0.0196, Training F1-score: 0.8270, Validation F1-score: 0.7620\n",
            "Epoch [10/10], Loss: 0.0228, Training F1-score: 0.8433, Validation F1-score: 0.7603\n",
            "Best validation score for iterations #1: 0.7671821305841925\n",
            "new config\n",
            "{'hidden_size': 141, 'lr': 0.003836224533938556, 'l2': 0.0001466745956732591, 'nonlin': 'relu', 'dropout': 0.2, 'num_layers': 1, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.6}\n",
            "Epoch [1/10], Loss: 0.0490, Training F1-score: 0.7089, Validation F1-score: 0.7363\n",
            "Epoch [2/10], Loss: 0.0687, Training F1-score: 0.7579, Validation F1-score: 0.7560\n",
            "Epoch [3/10], Loss: 0.0324, Training F1-score: 0.7228, Validation F1-score: 0.7139\n",
            "Epoch [4/10], Loss: 0.1042, Training F1-score: 0.7583, Validation F1-score: 0.7328\n",
            "Epoch [5/10], Loss: 0.0671, Training F1-score: 0.7796, Validation F1-score: 0.7500\n",
            "Epoch [6/10], Loss: 0.0736, Training F1-score: 0.7861, Validation F1-score: 0.7405\n",
            "Epoch [7/10], Loss: 0.0565, Training F1-score: 0.8091, Validation F1-score: 0.7371\n",
            "Epoch [8/10], Loss: 0.0749, Training F1-score: 0.7732, Validation F1-score: 0.7225\n",
            "Epoch [9/10], Loss: 0.0825, Training F1-score: 0.7714, Validation F1-score: 0.7363\n",
            "Epoch [10/10], Loss: 0.0489, Training F1-score: 0.7741, Validation F1-score: 0.7148\n",
            "Best validation score for iterations #2: 0.7560137457044673\n",
            "new config\n",
            "{'hidden_size': 269, 'lr': 0.001673120927857216, 'l2': 0.00044803008959205337, 'nonlin': 'relu', 'dropout': 0.1, 'num_layers': 1, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.30000000000000004}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.0401, Training F1-score: 0.7180, Validation F1-score: 0.7328\n",
            "Epoch [2/10], Loss: 0.0280, Training F1-score: 0.7268, Validation F1-score: 0.7199\n",
            "Epoch [3/10], Loss: 0.0376, Training F1-score: 0.7332, Validation F1-score: 0.7320\n",
            "Epoch [4/10], Loss: 0.0344, Training F1-score: 0.7255, Validation F1-score: 0.7259\n",
            "Epoch [5/10], Loss: 0.0470, Training F1-score: 0.7818, Validation F1-score: 0.7680\n",
            "Epoch [6/10], Loss: 0.0515, Training F1-score: 0.7927, Validation F1-score: 0.7560\n",
            "Epoch [7/10], Loss: 0.0437, Training F1-score: 0.7909, Validation F1-score: 0.7431\n",
            "Epoch [8/10], Loss: 0.0388, Training F1-score: 0.7758, Validation F1-score: 0.7320\n",
            "Epoch [9/10], Loss: 0.0372, Training F1-score: 0.8036, Validation F1-score: 0.7036\n",
            "Epoch [10/10], Loss: 0.0344, Training F1-score: 0.8212, Validation F1-score: 0.7062\n",
            "Best validation score for iterations #3: 0.7680412371134021\n",
            "new config\n",
            "{'hidden_size': 194, 'lr': 0.00035050251835192306, 'l2': 0.0002553507017480511, 'nonlin': 'tanh', 'dropout': 0.2, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.6}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.0265, Training F1-score: 0.7027, Validation F1-score: 0.6976\n",
            "Epoch [2/10], Loss: 0.0270, Training F1-score: 0.7397, Validation F1-score: 0.7397\n",
            "Epoch [3/10], Loss: 0.0249, Training F1-score: 0.7634, Validation F1-score: 0.7491\n",
            "Epoch [4/10], Loss: 0.0234, Training F1-score: 0.7691, Validation F1-score: 0.7577\n",
            "Epoch [5/10], Loss: 0.0222, Training F1-score: 0.7752, Validation F1-score: 0.7517\n",
            "Epoch [6/10], Loss: 0.0228, Training F1-score: 0.7798, Validation F1-score: 0.7448\n",
            "Epoch [7/10], Loss: 0.0209, Training F1-score: 0.7765, Validation F1-score: 0.7569\n",
            "Epoch [8/10], Loss: 0.0215, Training F1-score: 0.7796, Validation F1-score: 0.7569\n",
            "Epoch [9/10], Loss: 0.0191, Training F1-score: 0.7817, Validation F1-score: 0.7466\n",
            "Epoch [10/10], Loss: 0.0199, Training F1-score: 0.7881, Validation F1-score: 0.7259\n",
            "Best validation score for iterations #4: 0.7577319587628866\n",
            "new config\n",
            "{'hidden_size': 157, 'lr': 0.08096625285913045, 'l2': 2.1391914914709266e-05, 'nonlin': 'relu', 'dropout': 0.1, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.2}\n",
            "Epoch [1/10], Loss: 277219753822731294539510886432768.0000, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [2/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [3/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [4/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [5/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [6/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [7/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [8/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [9/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [10/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Best validation score for iterations #5: 0.7018900343642611\n",
            "new config\n",
            "{'hidden_size': 439, 'lr': 0.00014906478532667684, 'l2': 3.478087222010755e-05, 'nonlin': 'relu', 'dropout': 0.9, 'num_layers': 2, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.6}\n",
            "Epoch [1/10], Loss: 0.1164, Training F1-score: 0.6806, Validation F1-score: 0.7053\n",
            "Epoch [2/10], Loss: 0.0833, Training F1-score: 0.6782, Validation F1-score: 0.7053\n",
            "Epoch [3/10], Loss: 0.0585, Training F1-score: 0.6979, Validation F1-score: 0.7285\n",
            "Epoch [4/10], Loss: 0.0434, Training F1-score: 0.7091, Validation F1-score: 0.7320\n",
            "Epoch [5/10], Loss: 0.0346, Training F1-score: 0.7253, Validation F1-score: 0.7448\n",
            "Epoch [6/10], Loss: 0.0281, Training F1-score: 0.7375, Validation F1-score: 0.7466\n",
            "Epoch [7/10], Loss: 0.0235, Training F1-score: 0.7152, Validation F1-score: 0.7337\n",
            "Epoch [8/10], Loss: 0.0209, Training F1-score: 0.7211, Validation F1-score: 0.7371\n",
            "Epoch [9/10], Loss: 0.0198, Training F1-score: 0.7546, Validation F1-score: 0.7620\n",
            "Epoch [10/10], Loss: 0.0194, Training F1-score: 0.7310, Validation F1-score: 0.7448\n",
            "Best validation score for iterations #6: 0.7620274914089346\n",
            "new config\n",
            "{'hidden_size': 444, 'lr': 0.0003105474842631776, 'l2': 2.9172366225548515e-05, 'nonlin': 'tanh', 'dropout': 0.4, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.4}\n",
            "Epoch [1/10], Loss: 0.0268, Training F1-score: 0.7036, Validation F1-score: 0.7122\n",
            "Epoch [2/10], Loss: 0.0280, Training F1-score: 0.7456, Validation F1-score: 0.7371\n",
            "Epoch [3/10], Loss: 0.0245, Training F1-score: 0.7493, Validation F1-score: 0.7251\n",
            "Epoch [4/10], Loss: 0.0220, Training F1-score: 0.7552, Validation F1-score: 0.7062\n",
            "Epoch [5/10], Loss: 0.0224, Training F1-score: 0.7664, Validation F1-score: 0.7027\n",
            "Epoch [6/10], Loss: 0.0224, Training F1-score: 0.7599, Validation F1-score: 0.6881\n",
            "Epoch [7/10], Loss: 0.0205, Training F1-score: 0.7535, Validation F1-score: 0.6976\n",
            "Epoch [8/10], Loss: 0.0207, Training F1-score: 0.7483, Validation F1-score: 0.6692\n",
            "Epoch [9/10], Loss: 0.0201, Training F1-score: 0.7684, Validation F1-score: 0.6959\n",
            "Epoch [10/10], Loss: 0.0199, Training F1-score: 0.7622, Validation F1-score: 0.6821\n",
            "Best validation score for iterations #7: 0.7371134020618557\n",
            "new config\n",
            "{'hidden_size': 312, 'lr': 0.002370879107958811, 'l2': 0.0005134619330615994, 'nonlin': 'tanh', 'dropout': 0.6, 'num_layers': 1, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.30000000000000004}\n",
            "Epoch [1/10], Loss: 0.0388, Training F1-score: 0.6856, Validation F1-score: 0.7027\n",
            "Epoch [2/10], Loss: 0.0446, Training F1-score: 0.6692, Validation F1-score: 0.6778\n",
            "Epoch [3/10], Loss: 0.0455, Training F1-score: 0.5803, Validation F1-score: 0.5842\n",
            "Epoch [4/10], Loss: 0.0444, Training F1-score: 0.7047, Validation F1-score: 0.7002\n",
            "Epoch [5/10], Loss: 0.0538, Training F1-score: 0.6896, Validation F1-score: 0.6950\n",
            "Epoch [6/10], Loss: 0.0675, Training F1-score: 0.7194, Validation F1-score: 0.7268\n",
            "Epoch [7/10], Loss: 0.0605, Training F1-score: 0.7117, Validation F1-score: 0.7113\n",
            "Epoch [8/10], Loss: 0.0559, Training F1-score: 0.7014, Validation F1-score: 0.7079\n",
            "Epoch [9/10], Loss: 0.0520, Training F1-score: 0.7143, Validation F1-score: 0.7131\n",
            "Epoch [10/10], Loss: 0.0435, Training F1-score: 0.6959, Validation F1-score: 0.7165\n",
            "Best validation score for iterations #8: 0.7268041237113402\n",
            "new config\n",
            "{'hidden_size': 141, 'lr': 0.002841099968135399, 'l2': 0.0030552786611849295, 'nonlin': 'tanh', 'dropout': 0.8, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.8}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.8 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.0392, Training F1-score: 0.7005, Validation F1-score: 0.6959\n",
            "Epoch [2/10], Loss: 0.0675, Training F1-score: 0.6900, Validation F1-score: 0.6838\n",
            "Epoch [3/10], Loss: 0.0871, Training F1-score: 0.6946, Validation F1-score: 0.7156\n",
            "Epoch [4/10], Loss: 0.0331, Training F1-score: 0.7310, Validation F1-score: 0.7388\n",
            "Epoch [5/10], Loss: 0.0448, Training F1-score: 0.6913, Validation F1-score: 0.7002\n",
            "Epoch [6/10], Loss: 0.0845, Training F1-score: 0.6972, Validation F1-score: 0.6864\n",
            "Epoch [7/10], Loss: 0.0738, Training F1-score: 0.6994, Validation F1-score: 0.7139\n",
            "Epoch [8/10], Loss: 0.0516, Training F1-score: 0.6905, Validation F1-score: 0.6907\n",
            "Epoch [9/10], Loss: 0.0632, Training F1-score: 0.6644, Validation F1-score: 0.6615\n",
            "Epoch [10/10], Loss: 0.0580, Training F1-score: 0.7010, Validation F1-score: 0.7088\n",
            "Best validation score for iterations #9: 0.738831615120275\n",
            "new config\n",
            "{'hidden_size': 452, 'lr': 0.003947085992764816, 'l2': 0.004432902132102816, 'nonlin': 'relu', 'dropout': 0.7000000000000001, 'num_layers': 1, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.5}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.7000000000000001 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.0605, Training F1-score: 0.6891, Validation F1-score: 0.7027\n",
            "Epoch [2/10], Loss: 0.0933, Training F1-score: 0.7172, Validation F1-score: 0.7242\n",
            "Epoch [3/10], Loss: 0.0745, Training F1-score: 0.5994, Validation F1-score: 0.5782\n",
            "Epoch [4/10], Loss: 0.0580, Training F1-score: 0.6786, Validation F1-score: 0.6744\n",
            "Epoch [5/10], Loss: 0.0716, Training F1-score: 0.7071, Validation F1-score: 0.7165\n",
            "Epoch [6/10], Loss: 0.0811, Training F1-score: 0.7378, Validation F1-score: 0.7302\n",
            "Epoch [7/10], Loss: 0.0450, Training F1-score: 0.7189, Validation F1-score: 0.7148\n",
            "Epoch [8/10], Loss: 0.0738, Training F1-score: 0.7274, Validation F1-score: 0.7371\n",
            "Epoch [9/10], Loss: 0.0436, Training F1-score: 0.7305, Validation F1-score: 0.7320\n",
            "Epoch [10/10], Loss: 0.0383, Training F1-score: 0.7202, Validation F1-score: 0.7070\n",
            "Best validation score for iterations #10: 0.7371134020618557\n",
            "new config\n",
            "{'hidden_size': 466, 'lr': 0.00010575307415560996, 'l2': 0.0023543502933310663, 'nonlin': 'tanh', 'dropout': 0.5, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.8}\n",
            "Epoch [1/10], Loss: 0.0513, Training F1-score: 0.6990, Validation F1-score: 0.7105\n",
            "Epoch [2/10], Loss: 0.0435, Training F1-score: 0.7329, Validation F1-score: 0.7517\n",
            "Epoch [3/10], Loss: 0.0382, Training F1-score: 0.7007, Validation F1-score: 0.7045\n",
            "Epoch [4/10], Loss: 0.0340, Training F1-score: 0.7465, Validation F1-score: 0.7414\n",
            "Epoch [5/10], Loss: 0.0299, Training F1-score: 0.7555, Validation F1-score: 0.7423\n",
            "Epoch [6/10], Loss: 0.0258, Training F1-score: 0.7607, Validation F1-score: 0.7423\n",
            "Epoch [7/10], Loss: 0.0228, Training F1-score: 0.7640, Validation F1-score: 0.7517\n",
            "Epoch [8/10], Loss: 0.0200, Training F1-score: 0.7749, Validation F1-score: 0.7577\n",
            "Epoch [9/10], Loss: 0.0184, Training F1-score: 0.7811, Validation F1-score: 0.7560\n",
            "Epoch [10/10], Loss: 0.0190, Training F1-score: 0.7911, Validation F1-score: 0.7680\n",
            "Best validation score for iterations #11: 0.7680412371134021\n",
            "new config\n",
            "{'hidden_size': 116, 'lr': 0.0013537446329840253, 'l2': 0.00200481758276449, 'nonlin': 'relu', 'dropout': 0.2, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.4}\n",
            "Epoch [1/10], Loss: 0.0365, Training F1-score: 0.7025, Validation F1-score: 0.7113\n",
            "Epoch [2/10], Loss: 0.0325, Training F1-score: 0.7145, Validation F1-score: 0.7208\n",
            "Epoch [3/10], Loss: 0.0577, Training F1-score: 0.7172, Validation F1-score: 0.7320\n",
            "Epoch [4/10], Loss: 0.0312, Training F1-score: 0.7428, Validation F1-score: 0.7509\n",
            "Epoch [5/10], Loss: 0.0235, Training F1-score: 0.7559, Validation F1-score: 0.7500\n",
            "Epoch [6/10], Loss: 0.0450, Training F1-score: 0.7373, Validation F1-score: 0.7414\n",
            "Epoch [7/10], Loss: 0.0402, Training F1-score: 0.7555, Validation F1-score: 0.7552\n",
            "Epoch [8/10], Loss: 0.0403, Training F1-score: 0.7605, Validation F1-score: 0.7457\n",
            "Epoch [9/10], Loss: 0.0251, Training F1-score: 0.7555, Validation F1-score: 0.7483\n",
            "Epoch [10/10], Loss: 0.0364, Training F1-score: 0.7809, Validation F1-score: 0.7526\n",
            "Best validation score for iterations #12: 0.7551546391752577\n",
            "new config\n",
            "{'hidden_size': 280, 'lr': 0.009696091754042244, 'l2': 0.0001998065413157016, 'nonlin': 'tanh', 'dropout': 0.9, 'num_layers': 1, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.6}\n",
            "Epoch [1/10], Loss: 0.1079, Training F1-score: 0.4243, Validation F1-score: 0.4192\n",
            "Epoch [2/10], Loss: 0.2024, Training F1-score: 0.4691, Validation F1-score: 0.4519\n",
            "Epoch [3/10], Loss: 0.1830, Training F1-score: 0.5407, Validation F1-score: 0.5137\n",
            "Epoch [4/10], Loss: 0.1194, Training F1-score: 0.4615, Validation F1-score: 0.4201\n",
            "Epoch [5/10], Loss: 0.1505, Training F1-score: 0.4805, Validation F1-score: 0.4493\n",
            "Epoch [6/10], Loss: 0.0979, Training F1-score: 0.4687, Validation F1-score: 0.4364\n",
            "Epoch [7/10], Loss: 0.1682, Training F1-score: 0.4416, Validation F1-score: 0.4167\n",
            "Epoch [8/10], Loss: 0.0970, Training F1-score: 0.5125, Validation F1-score: 0.4674\n",
            "Epoch [9/10], Loss: 0.1452, Training F1-score: 0.4943, Validation F1-score: 0.4588\n",
            "Epoch [10/10], Loss: 0.1396, Training F1-score: 0.4939, Validation F1-score: 0.4639\n",
            "Best validation score for iterations #13: 0.5137457044673539\n",
            "new config\n",
            "{'hidden_size': 124, 'lr': 0.05623595571263542, 'l2': 0.000775607718327051, 'nonlin': 'relu', 'dropout': 0.6, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.5}\n",
            "Epoch [1/10], Loss: 23837377633393810866176.0000, Training F1-score: 0.4389, Validation F1-score: 0.4373\n",
            "Epoch [2/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [3/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [4/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [5/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [6/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [7/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [8/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [9/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Epoch [10/10], Loss: nan, Training F1-score: 0.6835, Validation F1-score: 0.7019\n",
            "Best validation score for iterations #14: 0.7018900343642611\n",
            "new config\n",
            "{'hidden_size': 438, 'lr': 0.01748974763642541, 'l2': 0.0015537300011972976, 'nonlin': 'relu', 'dropout': 0.4, 'num_layers': 1, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.7000000000000001}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.4 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.2269, Training F1-score: 0.6957, Validation F1-score: 0.7070\n",
            "Epoch [2/10], Loss: 0.1761, Training F1-score: 0.6756, Validation F1-score: 0.6607\n",
            "Epoch [3/10], Loss: 0.2968, Training F1-score: 0.6973, Validation F1-score: 0.7062\n",
            "Epoch [4/10], Loss: 0.2645, Training F1-score: 0.6627, Validation F1-score: 0.6314\n",
            "Epoch [5/10], Loss: 0.1705, Training F1-score: 0.6824, Validation F1-score: 0.6838\n",
            "Epoch [6/10], Loss: 0.2659, Training F1-score: 0.6867, Validation F1-score: 0.6993\n",
            "Epoch [7/10], Loss: 0.1973, Training F1-score: 0.6799, Validation F1-score: 0.6830\n",
            "Epoch [8/10], Loss: 0.2873, Training F1-score: 0.6916, Validation F1-score: 0.6967\n",
            "Epoch [9/10], Loss: 0.1285, Training F1-score: 0.6872, Validation F1-score: 0.7002\n",
            "Epoch [10/10], Loss: 0.0940, Training F1-score: 0.6508, Validation F1-score: 0.6529\n",
            "Best validation score for iterations #15: 0.7070446735395189\n",
            "new config\n",
            "{'hidden_size': 106, 'lr': 0.07691289574504478, 'l2': 8.127899394692977e-05, 'nonlin': 'tanh', 'dropout': 0.6, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.2}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.6 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.8252, Training F1-score: 0.6487, Validation F1-score: 0.6632\n",
            "Epoch [2/10], Loss: 0.3822, Training F1-score: 0.6563, Validation F1-score: 0.6624\n",
            "Epoch [3/10], Loss: 0.8980, Training F1-score: 0.6427, Validation F1-score: 0.6632\n",
            "Epoch [4/10], Loss: 1.9038, Training F1-score: 0.6920, Validation F1-score: 0.7062\n",
            "Epoch [5/10], Loss: 1.3741, Training F1-score: 0.6563, Validation F1-score: 0.6658\n",
            "Epoch [6/10], Loss: 0.9441, Training F1-score: 0.6793, Validation F1-score: 0.6847\n",
            "Epoch [7/10], Loss: 1.4423, Training F1-score: 0.6894, Validation F1-score: 0.7027\n",
            "Epoch [8/10], Loss: 0.7231, Training F1-score: 0.6690, Validation F1-score: 0.6753\n",
            "Epoch [9/10], Loss: 1.5772, Training F1-score: 0.6513, Validation F1-score: 0.6589\n",
            "Epoch [10/10], Loss: 0.4827, Training F1-score: 0.6646, Validation F1-score: 0.6615\n",
            "Best validation score for iterations #16: 0.7061855670103093\n",
            "new config\n",
            "{'hidden_size': 480, 'lr': 0.012764324710249441, 'l2': 0.008239299817378275, 'nonlin': 'relu', 'dropout': 0.1, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.30000000000000004}\n",
            "Epoch [1/10], Loss: 0.1258, Training F1-score: 0.6800, Validation F1-score: 0.6796\n",
            "Epoch [2/10], Loss: 0.1154, Training F1-score: 0.6778, Validation F1-score: 0.6838\n",
            "Epoch [3/10], Loss: 0.2929, Training F1-score: 0.6929, Validation F1-score: 0.7036\n",
            "Epoch [4/10], Loss: 0.1785, Training F1-score: 0.6762, Validation F1-score: 0.6864\n",
            "Epoch [5/10], Loss: 0.2573, Training F1-score: 0.6918, Validation F1-score: 0.7002\n",
            "Epoch [6/10], Loss: 0.1233, Training F1-score: 0.6832, Validation F1-score: 0.6881\n",
            "Epoch [7/10], Loss: 0.2092, Training F1-score: 0.6848, Validation F1-score: 0.6907\n",
            "Epoch [8/10], Loss: 0.2276, Training F1-score: 0.6887, Validation F1-score: 0.6993\n",
            "Epoch [9/10], Loss: 541974618916.0098, Training F1-score: 0.2844, Validation F1-score: 0.2603\n",
            "Epoch [10/10], Loss: 1621773.8236, Training F1-score: 0.1642, Validation F1-score: 0.1598\n",
            "Best validation score for iterations #17: 0.7036082474226805\n",
            "new config\n",
            "{'hidden_size': 309, 'lr': 0.015149243953222442, 'l2': 0.0005040930784325788, 'nonlin': 'relu', 'dropout': 0.1, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.30000000000000004}\n",
            "Epoch [1/10], Loss: 0.1350, Training F1-score: 0.6920, Validation F1-score: 0.6933\n",
            "Epoch [2/10], Loss: 0.2031, Training F1-score: 0.6574, Validation F1-score: 0.6538\n",
            "Epoch [3/10], Loss: 0.3242, Training F1-score: 0.6927, Validation F1-score: 0.7062\n",
            "Epoch [4/10], Loss: 0.2454, Training F1-score: 0.6968, Validation F1-score: 0.6993\n",
            "Epoch [5/10], Loss: 0.1945, Training F1-score: 0.6775, Validation F1-score: 0.6864\n",
            "Epoch [6/10], Loss: 229.5502, Training F1-score: 0.2697, Validation F1-score: 0.2612\n",
            "Epoch [7/10], Loss: 1459466.7308, Training F1-score: 0.1701, Validation F1-score: 0.1830\n",
            "Epoch [8/10], Loss: 2205.1557, Training F1-score: 0.6189, Validation F1-score: 0.6194\n",
            "Epoch [9/10], Loss: 1466.1274, Training F1-score: 0.6679, Validation F1-score: 0.6770\n",
            "Epoch [10/10], Loss: 218654374.3720, Training F1-score: 0.3351, Validation F1-score: 0.3419\n",
            "Best validation score for iterations #18: 0.7061855670103093\n",
            "new config\n",
            "{'hidden_size': 335, 'lr': 0.0008997379931247027, 'l2': 1.3371851988831439e-05, 'nonlin': 'tanh', 'dropout': 0.2, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.7000000000000001}\n",
            "Epoch [1/10], Loss: 0.0293, Training F1-score: 0.7165, Validation F1-score: 0.7500\n",
            "Epoch [2/10], Loss: 0.0275, Training F1-score: 0.7432, Validation F1-score: 0.7079\n",
            "Epoch [3/10], Loss: 0.0386, Training F1-score: 0.7471, Validation F1-score: 0.7320\n",
            "Epoch [4/10], Loss: 0.0366, Training F1-score: 0.7384, Validation F1-score: 0.7277\n",
            "Epoch [5/10], Loss: 0.0273, Training F1-score: 0.7003, Validation F1-score: 0.6959\n",
            "Epoch [6/10], Loss: 0.0374, Training F1-score: 0.7417, Validation F1-score: 0.7191\n",
            "Epoch [7/10], Loss: 0.0297, Training F1-score: 0.7355, Validation F1-score: 0.7191\n",
            "Epoch [8/10], Loss: 0.0299, Training F1-score: 0.7104, Validation F1-score: 0.6856\n",
            "Epoch [9/10], Loss: 0.0301, Training F1-score: 0.7139, Validation F1-score: 0.7174\n",
            "Epoch [10/10], Loss: 0.0290, Training F1-score: 0.7253, Validation F1-score: 0.7354\n",
            "Best validation score for iterations #19: 0.75\n",
            "************* Architecture: gru *************\n",
            "new config\n",
            "{'hidden_size': 409, 'lr': 0.01268528027569628, 'l2': 0.005152869238140152, 'nonlin': 'relu', 'dropout': 0.1, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.4}\n",
            "Epoch [1/10], Loss: 0.1047, Training F1-score: 0.6850, Validation F1-score: 0.6830\n",
            "Epoch [2/10], Loss: 0.2594, Training F1-score: 0.6826, Validation F1-score: 0.6838\n",
            "Epoch [3/10], Loss: 0.2064, Training F1-score: 0.7080, Validation F1-score: 0.7045\n",
            "Epoch [4/10], Loss: 0.1295, Training F1-score: 0.7456, Validation F1-score: 0.7363\n",
            "Epoch [5/10], Loss: 0.2007, Training F1-score: 0.7080, Validation F1-score: 0.7027\n",
            "Epoch [6/10], Loss: 0.1804, Training F1-score: 0.7101, Validation F1-score: 0.7010\n",
            "Epoch [7/10], Loss: 0.1339, Training F1-score: 0.7091, Validation F1-score: 0.6881\n",
            "Epoch [8/10], Loss: 0.2054, Training F1-score: 0.6880, Validation F1-score: 0.6624\n",
            "Epoch [9/10], Loss: 0.1167, Training F1-score: 0.5342, Validation F1-score: 0.5558\n",
            "Epoch [10/10], Loss: 0.1910, Training F1-score: 0.6340, Validation F1-score: 0.6211\n",
            "Best validation score for iterations #0: 0.736254295532646\n",
            "new config\n",
            "{'hidden_size': 479, 'lr': 0.0036633098761486597, 'l2': 8.647345950257379e-05, 'nonlin': 'tanh', 'dropout': 0.1, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.6}\n",
            "Epoch [1/10], Loss: 0.0592, Training F1-score: 0.7439, Validation F1-score: 0.7663\n",
            "Epoch [2/10], Loss: 0.0338, Training F1-score: 0.7426, Validation F1-score: 0.7225\n",
            "Epoch [3/10], Loss: 0.0547, Training F1-score: 0.7813, Validation F1-score: 0.7560\n",
            "Epoch [4/10], Loss: 0.0801, Training F1-score: 0.8025, Validation F1-score: 0.7680\n",
            "Epoch [5/10], Loss: 0.0857, Training F1-score: 0.8327, Validation F1-score: 0.7741\n",
            "Epoch [6/10], Loss: 0.0667, Training F1-score: 0.8461, Validation F1-score: 0.7792\n",
            "Epoch [7/10], Loss: 0.0709, Training F1-score: 0.8667, Validation F1-score: 0.7595\n",
            "Epoch [8/10], Loss: 0.0317, Training F1-score: 0.8927, Validation F1-score: 0.7448\n",
            "Epoch [9/10], Loss: 0.0628, Training F1-score: 0.8995, Validation F1-score: 0.7620\n",
            "Epoch [10/10], Loss: 0.0509, Training F1-score: 0.9111, Validation F1-score: 0.7526\n",
            "Best validation score for iterations #1: 0.7792096219931272\n",
            "new config\n",
            "{'hidden_size': 386, 'lr': 0.0024906056751463814, 'l2': 0.0005034063109483731, 'nonlin': 'relu', 'dropout': 0.8, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.2}\n",
            "Epoch [1/10], Loss: 0.0353, Training F1-score: 0.7616, Validation F1-score: 0.7689\n",
            "Epoch [2/10], Loss: 0.0379, Training F1-score: 0.7596, Validation F1-score: 0.7560\n",
            "Epoch [3/10], Loss: 0.0444, Training F1-score: 0.7774, Validation F1-score: 0.7680\n",
            "Epoch [4/10], Loss: 0.0764, Training F1-score: 0.8015, Validation F1-score: 0.7792\n",
            "Epoch [5/10], Loss: 0.0676, Training F1-score: 0.8036, Validation F1-score: 0.7758\n",
            "Epoch [6/10], Loss: 0.0428, Training F1-score: 0.8052, Validation F1-score: 0.7809\n",
            "Epoch [7/10], Loss: 0.0496, Training F1-score: 0.8360, Validation F1-score: 0.7646\n",
            "Epoch [8/10], Loss: 0.0457, Training F1-score: 0.8345, Validation F1-score: 0.7466\n",
            "Epoch [9/10], Loss: 0.0422, Training F1-score: 0.8584, Validation F1-score: 0.7569\n",
            "Epoch [10/10], Loss: 0.0399, Training F1-score: 0.8619, Validation F1-score: 0.7749\n",
            "Best validation score for iterations #2: 0.7809278350515464\n",
            "new config\n",
            "{'hidden_size': 361, 'lr': 0.02727548435934295, 'l2': 0.004549209491421694, 'nonlin': 'relu', 'dropout': 0.8, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.8}\n",
            "Epoch [1/10], Loss: 0.2282, Training F1-score: 0.6592, Validation F1-score: 0.6649\n",
            "Epoch [2/10], Loss: 0.5225, Training F1-score: 0.6985, Validation F1-score: 0.7036\n",
            "Epoch [3/10], Loss: 0.2799, Training F1-score: 0.6721, Validation F1-score: 0.6881\n",
            "Epoch [4/10], Loss: 0.5780, Training F1-score: 0.6953, Validation F1-score: 0.7216\n",
            "Epoch [5/10], Loss: 0.2738, Training F1-score: 0.6939, Validation F1-score: 0.7096\n",
            "Epoch [6/10], Loss: 0.3847, Training F1-score: 0.6885, Validation F1-score: 0.7113\n",
            "Epoch [7/10], Loss: 0.3382, Training F1-score: 0.7001, Validation F1-score: 0.6967\n",
            "Epoch [8/10], Loss: 0.1956, Training F1-score: 0.6957, Validation F1-score: 0.7070\n",
            "Epoch [9/10], Loss: 0.1244, Training F1-score: 0.6497, Validation F1-score: 0.6168\n",
            "Epoch [10/10], Loss: 0.1158, Training F1-score: 0.6924, Validation F1-score: 0.7019\n",
            "Best validation score for iterations #3: 0.7216494845360826\n",
            "new config\n",
            "{'hidden_size': 401, 'lr': 0.09335739154729926, 'l2': 2.354459027471783e-05, 'nonlin': 'tanh', 'dropout': 0.9, 'num_layers': 1, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.4}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.9 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.6762, Training F1-score: 0.5996, Validation F1-score: 0.6082\n",
            "Epoch [2/10], Loss: 1.2952, Training F1-score: 0.6771, Validation F1-score: 0.6813\n",
            "Epoch [3/10], Loss: 0.3363, Training F1-score: 0.6607, Validation F1-score: 0.6624\n",
            "Epoch [4/10], Loss: 2.3181, Training F1-score: 0.7224, Validation F1-score: 0.6864\n",
            "Epoch [5/10], Loss: 1.0739, Training F1-score: 0.6900, Validation F1-score: 0.6924\n",
            "Epoch [6/10], Loss: 1.8884, Training F1-score: 0.6951, Validation F1-score: 0.7139\n",
            "Epoch [7/10], Loss: 1.0974, Training F1-score: 0.7049, Validation F1-score: 0.6667\n",
            "Epoch [8/10], Loss: 1.6857, Training F1-score: 0.6944, Validation F1-score: 0.6692\n",
            "Epoch [9/10], Loss: 0.9730, Training F1-score: 0.6891, Validation F1-score: 0.7002\n",
            "Epoch [10/10], Loss: 0.8919, Training F1-score: 0.7150, Validation F1-score: 0.6942\n",
            "Best validation score for iterations #4: 0.7139175257731959\n",
            "new config\n",
            "{'hidden_size': 226, 'lr': 0.0010273193521579736, 'l2': 0.0008963885814396396, 'nonlin': 'tanh', 'dropout': 0.1, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.30000000000000004}\n",
            "Epoch [1/10], Loss: 0.0444, Training F1-score: 0.7590, Validation F1-score: 0.7500\n",
            "Epoch [2/10], Loss: 0.0327, Training F1-score: 0.7664, Validation F1-score: 0.7620\n",
            "Epoch [3/10], Loss: 0.0277, Training F1-score: 0.7710, Validation F1-score: 0.7715\n",
            "Epoch [4/10], Loss: 0.0258, Training F1-score: 0.7853, Validation F1-score: 0.7852\n",
            "Epoch [5/10], Loss: 0.0188, Training F1-score: 0.7870, Validation F1-score: 0.7818\n",
            "Epoch [6/10], Loss: 0.0261, Training F1-score: 0.7912, Validation F1-score: 0.7784\n",
            "Epoch [7/10], Loss: 0.0253, Training F1-score: 0.8025, Validation F1-score: 0.7809\n",
            "Epoch [8/10], Loss: 0.0183, Training F1-score: 0.8050, Validation F1-score: 0.7758\n",
            "Epoch [9/10], Loss: 0.0348, Training F1-score: 0.8154, Validation F1-score: 0.7775\n",
            "Epoch [10/10], Loss: 0.0380, Training F1-score: 0.8229, Validation F1-score: 0.7655\n",
            "Best validation score for iterations #5: 0.7852233676975945\n",
            "new config\n",
            "{'hidden_size': 302, 'lr': 0.00010769630091763721, 'l2': 2.5888680371842294e-05, 'nonlin': 'tanh', 'dropout': 0.1, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.1}\n",
            "Epoch [1/10], Loss: 0.0486, Training F1-score: 0.7031, Validation F1-score: 0.7113\n",
            "Epoch [2/10], Loss: 0.0390, Training F1-score: 0.7507, Validation F1-score: 0.7663\n",
            "Epoch [3/10], Loss: 0.0331, Training F1-score: 0.7647, Validation F1-score: 0.7680\n",
            "Epoch [4/10], Loss: 0.0287, Training F1-score: 0.7706, Validation F1-score: 0.7723\n",
            "Epoch [5/10], Loss: 0.0245, Training F1-score: 0.7741, Validation F1-score: 0.7801\n",
            "Epoch [6/10], Loss: 0.0206, Training F1-score: 0.7817, Validation F1-score: 0.7835\n",
            "Epoch [7/10], Loss: 0.0187, Training F1-score: 0.7844, Validation F1-score: 0.7809\n",
            "Epoch [8/10], Loss: 0.0181, Training F1-score: 0.7865, Validation F1-score: 0.7844\n",
            "Epoch [9/10], Loss: 0.0178, Training F1-score: 0.7905, Validation F1-score: 0.7826\n",
            "Epoch [10/10], Loss: 0.0175, Training F1-score: 0.7946, Validation F1-score: 0.7826\n",
            "Best validation score for iterations #6: 0.7843642611683849\n",
            "new config\n",
            "{'hidden_size': 235, 'lr': 0.006945122239183134, 'l2': 0.0033286200824508253, 'nonlin': 'relu', 'dropout': 0.2, 'num_layers': 2, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.30000000000000004}\n",
            "Epoch [1/10], Loss: 0.1019, Training F1-score: 0.6955, Validation F1-score: 0.7191\n",
            "Epoch [2/10], Loss: 0.1205, Training F1-score: 0.7539, Validation F1-score: 0.7560\n",
            "Epoch [3/10], Loss: 0.1310, Training F1-score: 0.7568, Validation F1-score: 0.7612\n",
            "Epoch [4/10], Loss: 0.0885, Training F1-score: 0.7561, Validation F1-score: 0.7526\n",
            "Epoch [5/10], Loss: 0.1103, Training F1-score: 0.7533, Validation F1-score: 0.7491\n",
            "Epoch [6/10], Loss: 0.1024, Training F1-score: 0.7507, Validation F1-score: 0.7491\n",
            "Epoch [7/10], Loss: 0.0745, Training F1-score: 0.7594, Validation F1-score: 0.7500\n",
            "Epoch [8/10], Loss: 0.1018, Training F1-score: 0.7623, Validation F1-score: 0.7603\n",
            "Epoch [9/10], Loss: 0.0733, Training F1-score: 0.7513, Validation F1-score: 0.7371\n",
            "Epoch [10/10], Loss: 0.0984, Training F1-score: 0.7649, Validation F1-score: 0.7517\n",
            "Best validation score for iterations #7: 0.761168384879725\n",
            "new config\n",
            "{'hidden_size': 280, 'lr': 0.0009335082900950635, 'l2': 3.662867180005758e-05, 'nonlin': 'relu', 'dropout': 0.7000000000000001, 'num_layers': 1, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.1}\n",
            "Epoch [1/10], Loss: 0.0292, Training F1-score: 0.7553, Validation F1-score: 0.7646\n",
            "Epoch [2/10], Loss: 0.0371, Training F1-score: 0.7754, Validation F1-score: 0.7698\n",
            "Epoch [3/10], Loss: 0.0322, Training F1-score: 0.7881, Validation F1-score: 0.7861\n",
            "Epoch [4/10], Loss: 0.0303, Training F1-score: 0.8091, Validation F1-score: 0.7741\n",
            "Epoch [5/10], Loss: 0.0283, Training F1-score: 0.8211, Validation F1-score: 0.7612\n",
            "Epoch [6/10], Loss: 0.0255, Training F1-score: 0.8351, Validation F1-score: 0.7457\n",
            "Epoch [7/10], Loss: 0.0266, Training F1-score: 0.8279, Validation F1-score: 0.7027\n",
            "Epoch [8/10], Loss: 0.0237, Training F1-score: 0.8564, Validation F1-score: 0.6899\n",
            "Epoch [9/10], Loss: 0.0180, Training F1-score: 0.8452, Validation F1-score: 0.6856\n",
            "Epoch [10/10], Loss: 0.0163, Training F1-score: 0.9046, Validation F1-score: 0.7096\n",
            "Best validation score for iterations #8: 0.7860824742268041\n",
            "new config\n",
            "{'hidden_size': 178, 'lr': 0.0714815970161965, 'l2': 1.1155163101726145e-05, 'nonlin': 'tanh', 'dropout': 0.5, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.9}\n",
            "Epoch [1/10], Loss: 0.4647, Training F1-score: 0.6449, Validation F1-score: 0.6392\n",
            "Epoch [2/10], Loss: 1.2067, Training F1-score: 0.6837, Validation F1-score: 0.7131\n",
            "Epoch [3/10], Loss: 0.7424, Training F1-score: 0.6872, Validation F1-score: 0.7122\n",
            "Epoch [4/10], Loss: 0.8820, Training F1-score: 0.6913, Validation F1-score: 0.6967\n",
            "Epoch [5/10], Loss: 0.2570, Training F1-score: 0.6427, Validation F1-score: 0.6460\n",
            "Epoch [6/10], Loss: 1.6963, Training F1-score: 0.6880, Validation F1-score: 0.7113\n",
            "Epoch [7/10], Loss: 0.8368, Training F1-score: 0.6633, Validation F1-score: 0.6761\n",
            "Epoch [8/10], Loss: 1.3687, Training F1-score: 0.7031, Validation F1-score: 0.7079\n",
            "Epoch [9/10], Loss: 0.7957, Training F1-score: 0.6732, Validation F1-score: 0.6873\n",
            "Epoch [10/10], Loss: 0.8329, Training F1-score: 0.6736, Validation F1-score: 0.6830\n",
            "Best validation score for iterations #9: 0.7130584192439863\n",
            "new config\n",
            "{'hidden_size': 379, 'lr': 0.07314396763797731, 'l2': 0.00048273055715546495, 'nonlin': 'relu', 'dropout': 0.8, 'num_layers': 1, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.5}\n",
            "Epoch [1/10], Loss: 0.4891, Training F1-score: 0.6434, Validation F1-score: 0.6375\n",
            "Epoch [2/10], Loss: 1.1911, Training F1-score: 0.6826, Validation F1-score: 0.6649\n",
            "Epoch [3/10], Loss: 0.2270, Training F1-score: 0.6416, Validation F1-score: 0.6392\n",
            "Epoch [4/10], Loss: 2.0591, Training F1-score: 0.6916, Validation F1-score: 0.6950\n",
            "Epoch [5/10], Loss: 0.7479, Training F1-score: 0.6296, Validation F1-score: 0.6177\n",
            "Epoch [6/10], Loss: 1.7017, Training F1-score: 0.6869, Validation F1-score: 0.7027\n",
            "Epoch [7/10], Loss: 0.6706, Training F1-score: 0.6858, Validation F1-score: 0.7019\n",
            "Epoch [8/10], Loss: 0.8700, Training F1-score: 0.6661, Validation F1-score: 0.6770\n",
            "Epoch [9/10], Loss: 1.3763, Training F1-score: 0.6869, Validation F1-score: 0.6873\n",
            "Epoch [10/10], Loss: 0.5076, Training F1-score: 0.6846, Validation F1-score: 0.7019\n",
            "Best validation score for iterations #10: 0.7027491408934707\n",
            "new config\n",
            "{'hidden_size': 456, 'lr': 0.02808594297145665, 'l2': 0.00024068431110622977, 'nonlin': 'tanh', 'dropout': 0.1, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.30000000000000004}\n",
            "Epoch [1/10], Loss: 0.2131, Training F1-score: 0.6581, Validation F1-score: 0.6624\n",
            "Epoch [2/10], Loss: 0.3937, Training F1-score: 0.6889, Validation F1-score: 0.6916\n",
            "Epoch [3/10], Loss: 0.1073, Training F1-score: 0.6620, Validation F1-score: 0.6658\n",
            "Epoch [4/10], Loss: 0.7039, Training F1-score: 0.6904, Validation F1-score: 0.6950\n",
            "Epoch [5/10], Loss: 0.3341, Training F1-score: 0.6699, Validation F1-score: 0.6624\n",
            "Epoch [6/10], Loss: 0.6749, Training F1-score: 0.6683, Validation F1-score: 0.6787\n",
            "Epoch [7/10], Loss: 0.3084, Training F1-score: 0.6905, Validation F1-score: 0.6950\n",
            "Epoch [8/10], Loss: 0.4126, Training F1-score: 0.6922, Validation F1-score: 0.6985\n",
            "Epoch [9/10], Loss: 0.2853, Training F1-score: 0.6811, Validation F1-score: 0.6804\n",
            "Epoch [10/10], Loss: 0.4098, Training F1-score: 0.6916, Validation F1-score: 0.6838\n",
            "Best validation score for iterations #11: 0.6984536082474226\n",
            "new config\n",
            "{'hidden_size': 152, 'lr': 0.00043956835789194486, 'l2': 0.0001957426630898292, 'nonlin': 'relu', 'dropout': 0.1, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.6}\n",
            "Epoch [1/10], Loss: 0.0708, Training F1-score: 0.7137, Validation F1-score: 0.7388\n",
            "Epoch [2/10], Loss: 0.0466, Training F1-score: 0.7708, Validation F1-score: 0.7723\n",
            "Epoch [3/10], Loss: 0.0292, Training F1-score: 0.7750, Validation F1-score: 0.7775\n",
            "Epoch [4/10], Loss: 0.0245, Training F1-score: 0.7859, Validation F1-score: 0.7826\n",
            "Epoch [5/10], Loss: 0.0266, Training F1-score: 0.7923, Validation F1-score: 0.7844\n",
            "Epoch [6/10], Loss: 0.0186, Training F1-score: 0.7992, Validation F1-score: 0.7861\n",
            "Epoch [7/10], Loss: 0.0241, Training F1-score: 0.8054, Validation F1-score: 0.7861\n",
            "Epoch [8/10], Loss: 0.0208, Training F1-score: 0.8115, Validation F1-score: 0.7861\n",
            "Epoch [9/10], Loss: 0.0194, Training F1-score: 0.8187, Validation F1-score: 0.7792\n",
            "Epoch [10/10], Loss: 0.0203, Training F1-score: 0.8240, Validation F1-score: 0.7698\n",
            "Best validation score for iterations #12: 0.7860824742268041\n",
            "new config\n",
            "{'hidden_size': 280, 'lr': 0.036400460160537274, 'l2': 1.2310859804467374e-05, 'nonlin': 'tanh', 'dropout': 0.2, 'num_layers': 1, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.7000000000000001}\n",
            "Epoch [1/10], Loss: 0.3153, Training F1-score: 0.6915, Validation F1-score: 0.6778\n",
            "Epoch [2/10], Loss: 0.2990, Training F1-score: 0.6892, Validation F1-score: 0.7045\n",
            "Epoch [3/10], Loss: 0.7983, Training F1-score: 0.7393, Validation F1-score: 0.6924\n",
            "Epoch [4/10], Loss: 0.4672, Training F1-score: 0.6970, Validation F1-score: 0.6529\n",
            "Epoch [5/10], Loss: 0.6948, Training F1-score: 0.6983, Validation F1-score: 0.6727\n",
            "Epoch [6/10], Loss: 0.2755, Training F1-score: 0.7161, Validation F1-score: 0.6512\n",
            "Epoch [7/10], Loss: 0.6088, Training F1-score: 0.6823, Validation F1-score: 0.6040\n",
            "Epoch [8/10], Loss: 0.3507, Training F1-score: 0.7305, Validation F1-score: 0.6787\n",
            "Epoch [9/10], Loss: 0.5869, Training F1-score: 0.7117, Validation F1-score: 0.6426\n",
            "Epoch [10/10], Loss: 0.3278, Training F1-score: 0.6714, Validation F1-score: 0.5945\n",
            "Best validation score for iterations #13: 0.7044673539518901\n",
            "new config\n",
            "{'hidden_size': 380, 'lr': 0.06230262120060972, 'l2': 0.003646414461423442, 'nonlin': 'relu', 'dropout': 0.6, 'num_layers': 1, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.6}\n",
            "Epoch [1/10], Loss: 0.5734, Training F1-score: 0.6767, Validation F1-score: 0.6942\n",
            "Epoch [2/10], Loss: 0.8877, Training F1-score: 0.6596, Validation F1-score: 0.6701\n",
            "Epoch [3/10], Loss: 1.2498, Training F1-score: 0.6852, Validation F1-score: 0.7062\n",
            "Epoch [4/10], Loss: 0.7742, Training F1-score: 0.6843, Validation F1-score: 0.6976\n",
            "Epoch [5/10], Loss: 0.7711, Training F1-score: 0.6633, Validation F1-score: 0.6735\n",
            "Epoch [6/10], Loss: 1.1297, Training F1-score: 0.6856, Validation F1-score: 0.7045\n",
            "Epoch [7/10], Loss: 0.6080, Training F1-score: 0.6734, Validation F1-score: 0.6881\n",
            "Epoch [8/10], Loss: 0.9817, Training F1-score: 0.6867, Validation F1-score: 0.7139\n",
            "Epoch [9/10], Loss: 0.4297, Training F1-score: 0.6622, Validation F1-score: 0.6435\n",
            "Epoch [10/10], Loss: 0.3067, Training F1-score: 0.6460, Validation F1-score: 0.6469\n",
            "Best validation score for iterations #14: 0.7139175257731959\n",
            "new config\n",
            "{'hidden_size': 400, 'lr': 0.07578477820051702, 'l2': 0.005342624478033826, 'nonlin': 'relu', 'dropout': 0.30000000000000004, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.30000000000000004}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.30000000000000004 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.4562, Training F1-score: 0.6366, Validation F1-score: 0.6546\n",
            "Epoch [2/10], Loss: 1.2118, Training F1-score: 0.5523, Validation F1-score: 0.5395\n",
            "Epoch [3/10], Loss: 1.5417, Training F1-score: 0.6854, Validation F1-score: 0.7045\n",
            "Epoch [4/10], Loss: 0.7774, Training F1-score: 0.6675, Validation F1-score: 0.6813\n",
            "Epoch [5/10], Loss: 1.3709, Training F1-score: 0.6850, Validation F1-score: 0.7019\n",
            "Epoch [6/10], Loss: 0.8392, Training F1-score: 0.6697, Validation F1-score: 0.6821\n",
            "Epoch [7/10], Loss: 1.2670, Training F1-score: 0.6740, Validation F1-score: 0.6890\n",
            "Epoch [8/10], Loss: 0.6988, Training F1-score: 0.6762, Validation F1-score: 0.6916\n",
            "Epoch [9/10], Loss: 1.2232, Training F1-score: 0.6355, Validation F1-score: 0.6564\n",
            "Epoch [10/10], Loss: 0.5537, Training F1-score: 0.6832, Validation F1-score: 0.7019\n",
            "Best validation score for iterations #15: 0.7044673539518901\n",
            "new config\n",
            "{'hidden_size': 353, 'lr': 0.016707262110165218, 'l2': 3.576789060071812e-05, 'nonlin': 'relu', 'dropout': 0.1, 'num_layers': 1, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.9}\n",
            "Epoch [1/10], Loss: 0.1976, Training F1-score: 0.7215, Validation F1-score: 0.6838\n",
            "Epoch [2/10], Loss: 0.3167, Training F1-score: 0.7518, Validation F1-score: 0.7045\n",
            "Epoch [3/10], Loss: 0.2674, Training F1-score: 0.7655, Validation F1-score: 0.7191\n",
            "Epoch [4/10], Loss: 0.1929, Training F1-score: 0.7261, Validation F1-score: 0.6607\n",
            "Epoch [5/10], Loss: 0.2537, Training F1-score: 0.7174, Validation F1-score: 0.6787\n",
            "Epoch [6/10], Loss: 0.1779, Training F1-score: 0.7261, Validation F1-score: 0.6701\n",
            "Epoch [7/10], Loss: 0.2469, Training F1-score: 0.6679, Validation F1-score: 0.5971\n",
            "Epoch [8/10], Loss: 0.2306, Training F1-score: 0.7443, Validation F1-score: 0.6830\n",
            "Epoch [9/10], Loss: 0.2156, Training F1-score: 0.7231, Validation F1-score: 0.6546\n",
            "Epoch [10/10], Loss: 0.2114, Training F1-score: 0.7605, Validation F1-score: 0.6821\n",
            "Best validation score for iterations #16: 0.7190721649484536\n",
            "new config\n",
            "{'hidden_size': 443, 'lr': 0.0001592681597186771, 'l2': 1.173983569170755e-05, 'nonlin': 'tanh', 'dropout': 0.4, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.8}\n",
            "Epoch [1/10], Loss: 0.0656, Training F1-score: 0.7294, Validation F1-score: 0.7345\n",
            "Epoch [2/10], Loss: 0.0457, Training F1-score: 0.7583, Validation F1-score: 0.7663\n",
            "Epoch [3/10], Loss: 0.0346, Training F1-score: 0.7616, Validation F1-score: 0.7629\n",
            "Epoch [4/10], Loss: 0.0268, Training F1-score: 0.7741, Validation F1-score: 0.7655\n",
            "Epoch [5/10], Loss: 0.0242, Training F1-score: 0.7717, Validation F1-score: 0.7706\n",
            "Epoch [6/10], Loss: 0.0228, Training F1-score: 0.7795, Validation F1-score: 0.7672\n",
            "Epoch [7/10], Loss: 0.0214, Training F1-score: 0.7934, Validation F1-score: 0.7732\n",
            "Epoch [8/10], Loss: 0.0198, Training F1-score: 0.7984, Validation F1-score: 0.7758\n",
            "Epoch [9/10], Loss: 0.0181, Training F1-score: 0.8047, Validation F1-score: 0.7715\n",
            "Epoch [10/10], Loss: 0.0182, Training F1-score: 0.8060, Validation F1-score: 0.7637\n",
            "Best validation score for iterations #17: 0.7757731958762887\n",
            "new config\n",
            "{'hidden_size': 207, 'lr': 0.05079844029159006, 'l2': 2.3504108854014585e-05, 'nonlin': 'tanh', 'dropout': 0.30000000000000004, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.8}\n",
            "Epoch [1/10], Loss: 0.3722, Training F1-score: 0.6644, Validation F1-score: 0.6624\n",
            "Epoch [2/10], Loss: 0.9901, Training F1-score: 0.6850, Validation F1-score: 0.7088\n",
            "Epoch [3/10], Loss: 0.6209, Training F1-score: 0.6767, Validation F1-score: 0.6856\n",
            "Epoch [4/10], Loss: 0.8825, Training F1-score: 0.6858, Validation F1-score: 0.7105\n",
            "Epoch [5/10], Loss: 0.4527, Training F1-score: 0.6764, Validation F1-score: 0.6864\n",
            "Epoch [6/10], Loss: 0.7448, Training F1-score: 0.6834, Validation F1-score: 0.7045\n",
            "Epoch [7/10], Loss: 0.5379, Training F1-score: 0.6730, Validation F1-score: 0.6796\n",
            "Epoch [8/10], Loss: 0.8089, Training F1-score: 0.6832, Validation F1-score: 0.6649\n",
            "Epoch [9/10], Loss: 0.3593, Training F1-score: 0.6622, Validation F1-score: 0.6615\n",
            "Epoch [10/10], Loss: 0.6237, Training F1-score: 0.6940, Validation F1-score: 0.7088\n",
            "Best validation score for iterations #18: 0.7104810996563574\n",
            "new config\n",
            "{'hidden_size': 348, 'lr': 0.06853684437427839, 'l2': 1.6561439347714316e-05, 'nonlin': 'tanh', 'dropout': 0.8, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.2}\n",
            "Epoch [1/10], Loss: 0.5008, Training F1-score: 0.6616, Validation F1-score: 0.6753\n",
            "Epoch [2/10], Loss: 0.7873, Training F1-score: 0.5863, Validation F1-score: 0.5885\n",
            "Epoch [3/10], Loss: 1.2998, Training F1-score: 0.6151, Validation F1-score: 0.6177\n",
            "Epoch [4/10], Loss: 1.9778, Training F1-score: 0.6826, Validation F1-score: 0.6881\n",
            "Epoch [5/10], Loss: 0.6298, Training F1-score: 0.6753, Validation F1-score: 0.7019\n",
            "Epoch [6/10], Loss: 1.3417, Training F1-score: 0.6546, Validation F1-score: 0.6306\n",
            "Epoch [7/10], Loss: 0.8145, Training F1-score: 0.6793, Validation F1-score: 0.7010\n",
            "Epoch [8/10], Loss: 0.8473, Training F1-score: 0.6765, Validation F1-score: 0.6907\n",
            "Epoch [9/10], Loss: 1.1376, Training F1-score: 0.6331, Validation F1-score: 0.6194\n",
            "Epoch [10/10], Loss: 0.6601, Training F1-score: 0.6600, Validation F1-score: 0.6649\n",
            "Best validation score for iterations #19: 0.7018900343642611\n",
            "************* Architecture: lstm *************\n",
            "new config\n",
            "{'hidden_size': 497, 'lr': 0.028515208130274312, 'l2': 0.008785242426708554, 'nonlin': 'tanh', 'dropout': 0.5, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.5}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:61: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 0.2061, Training F1-score: 0.6499, Validation F1-score: 0.6581\n",
            "Epoch [2/10], Loss: 0.6580, Training F1-score: 0.6907, Validation F1-score: 0.7079\n",
            "Epoch [3/10], Loss: 0.3268, Training F1-score: 0.6565, Validation F1-score: 0.6538\n",
            "Epoch [4/10], Loss: 0.3218, Training F1-score: 0.6592, Validation F1-score: 0.6469\n",
            "Epoch [5/10], Loss: 0.3339, Training F1-score: 0.6445, Validation F1-score: 0.6177\n",
            "Epoch [6/10], Loss: 0.3044, Training F1-score: 0.6723, Validation F1-score: 0.6581\n",
            "Epoch [7/10], Loss: 0.3120, Training F1-score: 0.6414, Validation F1-score: 0.6289\n",
            "Epoch [8/10], Loss: 0.2921, Training F1-score: 0.6602, Validation F1-score: 0.6581\n",
            "Epoch [9/10], Loss: 0.3837, Training F1-score: 0.6322, Validation F1-score: 0.6134\n",
            "Epoch [10/10], Loss: 0.3693, Training F1-score: 0.6880, Validation F1-score: 0.6993\n",
            "Best validation score for iterations #0: 0.7079037800687286\n",
            "new config\n",
            "{'hidden_size': 354, 'lr': 0.00016522149282424393, 'l2': 0.007037724945218993, 'nonlin': 'tanh', 'dropout': 0.6, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.1}\n",
            "Epoch [1/10], Loss: 0.0466, Training F1-score: 0.6683, Validation F1-score: 0.6881\n",
            "Epoch [2/10], Loss: 0.0313, Training F1-score: 0.6992, Validation F1-score: 0.7199\n",
            "Epoch [3/10], Loss: 0.0262, Training F1-score: 0.7012, Validation F1-score: 0.7242\n",
            "Epoch [4/10], Loss: 0.0254, Training F1-score: 0.7021, Validation F1-score: 0.7337\n",
            "Epoch [5/10], Loss: 0.0248, Training F1-score: 0.7069, Validation F1-score: 0.7354\n",
            "Epoch [6/10], Loss: 0.0243, Training F1-score: 0.7115, Validation F1-score: 0.7440\n",
            "Epoch [7/10], Loss: 0.0238, Training F1-score: 0.7139, Validation F1-score: 0.7483\n",
            "Epoch [8/10], Loss: 0.0234, Training F1-score: 0.7180, Validation F1-score: 0.7491\n",
            "Epoch [9/10], Loss: 0.0230, Training F1-score: 0.7187, Validation F1-score: 0.7500\n",
            "Epoch [10/10], Loss: 0.0225, Training F1-score: 0.7189, Validation F1-score: 0.7534\n",
            "Best validation score for iterations #1: 0.7534364261168385\n",
            "new config\n",
            "{'hidden_size': 472, 'lr': 0.005108728276970762, 'l2': 0.0011348898790512934, 'nonlin': 'relu', 'dropout': 0.1, 'num_layers': 2, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.2}\n",
            "Epoch [1/10], Loss: 0.0560, Training F1-score: 0.6850, Validation F1-score: 0.6959\n",
            "Epoch [2/10], Loss: 0.1129, Training F1-score: 0.7307, Validation F1-score: 0.7345\n",
            "Epoch [3/10], Loss: 0.0912, Training F1-score: 0.7419, Validation F1-score: 0.7423\n",
            "Epoch [4/10], Loss: 0.0842, Training F1-score: 0.7511, Validation F1-score: 0.7491\n",
            "Epoch [5/10], Loss: 0.0782, Training F1-score: 0.7679, Validation F1-score: 0.7543\n",
            "Epoch [6/10], Loss: 0.0599, Training F1-score: 0.7736, Validation F1-score: 0.7569\n",
            "Epoch [7/10], Loss: 0.1102, Training F1-score: 0.7947, Validation F1-score: 0.7595\n",
            "Epoch [8/10], Loss: 0.0365, Training F1-score: 0.7969, Validation F1-score: 0.7586\n",
            "Epoch [9/10], Loss: 0.0333, Training F1-score: 0.7813, Validation F1-score: 0.7371\n",
            "Epoch [10/10], Loss: 0.0330, Training F1-score: 0.8012, Validation F1-score: 0.7637\n",
            "Best validation score for iterations #2: 0.7637457044673539\n",
            "new config\n",
            "{'hidden_size': 354, 'lr': 0.0012216493410293768, 'l2': 0.007453263505830272, 'nonlin': 'tanh', 'dropout': 0.30000000000000004, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.4}\n",
            "Epoch [1/10], Loss: 0.0342, Training F1-score: 0.6968, Validation F1-score: 0.7053\n",
            "Epoch [2/10], Loss: 0.0270, Training F1-score: 0.6883, Validation F1-score: 0.7070\n",
            "Epoch [3/10], Loss: 0.0338, Training F1-score: 0.7060, Validation F1-score: 0.7208\n",
            "Epoch [4/10], Loss: 0.0499, Training F1-score: 0.7158, Validation F1-score: 0.7328\n",
            "Epoch [5/10], Loss: 0.0451, Training F1-score: 0.7200, Validation F1-score: 0.7337\n",
            "Epoch [6/10], Loss: 0.0298, Training F1-score: 0.7239, Validation F1-score: 0.7320\n",
            "Epoch [7/10], Loss: 0.0412, Training F1-score: 0.7242, Validation F1-score: 0.7328\n",
            "Epoch [8/10], Loss: 0.0365, Training F1-score: 0.7268, Validation F1-score: 0.7363\n",
            "Epoch [9/10], Loss: 0.0314, Training F1-score: 0.7222, Validation F1-score: 0.7251\n",
            "Epoch [10/10], Loss: 0.0345, Training F1-score: 0.7272, Validation F1-score: 0.7208\n",
            "Best validation score for iterations #3: 0.736254295532646\n",
            "new config\n",
            "{'hidden_size': 302, 'lr': 0.0034272418389827666, 'l2': 0.0011915549075569624, 'nonlin': 'tanh', 'dropout': 0.6, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.1}\n",
            "Epoch [1/10], Loss: 0.0539, Training F1-score: 0.7099, Validation F1-score: 0.6924\n",
            "Epoch [2/10], Loss: 0.0825, Training F1-score: 0.7520, Validation F1-score: 0.7414\n",
            "Epoch [3/10], Loss: 0.0653, Training F1-score: 0.7752, Validation F1-score: 0.7663\n",
            "Epoch [4/10], Loss: 0.0612, Training F1-score: 0.7879, Validation F1-score: 0.7784\n",
            "Epoch [5/10], Loss: 0.0573, Training F1-score: 0.7973, Validation F1-score: 0.7741\n",
            "Epoch [6/10], Loss: 0.0543, Training F1-score: 0.7995, Validation F1-score: 0.7732\n",
            "Epoch [7/10], Loss: 0.0516, Training F1-score: 0.8049, Validation F1-score: 0.7689\n",
            "Epoch [8/10], Loss: 0.0400, Training F1-score: 0.8017, Validation F1-score: 0.7698\n",
            "Epoch [9/10], Loss: 0.0459, Training F1-score: 0.8047, Validation F1-score: 0.7543\n",
            "Epoch [10/10], Loss: 0.0498, Training F1-score: 0.8021, Validation F1-score: 0.7552\n",
            "Best validation score for iterations #4: 0.7783505154639175\n",
            "new config\n",
            "{'hidden_size': 425, 'lr': 0.005346716657395268, 'l2': 0.009759648257105779, 'nonlin': 'relu', 'dropout': 0.30000000000000004, 'num_layers': 1, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.2}\n",
            "Epoch [1/10], Loss: 0.0792, Training F1-score: 0.6968, Validation F1-score: 0.6993\n",
            "Epoch [2/10], Loss: 0.1171, Training F1-score: 0.7005, Validation F1-score: 0.7070\n",
            "Epoch [3/10], Loss: 0.0975, Training F1-score: 0.7189, Validation F1-score: 0.7242\n",
            "Epoch [4/10], Loss: 0.0750, Training F1-score: 0.7194, Validation F1-score: 0.7259\n",
            "Epoch [5/10], Loss: 0.0854, Training F1-score: 0.7220, Validation F1-score: 0.7337\n",
            "Epoch [6/10], Loss: 0.0917, Training F1-score: 0.7248, Validation F1-score: 0.7423\n",
            "Epoch [7/10], Loss: 0.0696, Training F1-score: 0.7154, Validation F1-score: 0.7242\n",
            "Epoch [8/10], Loss: 0.0979, Training F1-score: 0.7314, Validation F1-score: 0.7466\n",
            "Epoch [9/10], Loss: 0.0826, Training F1-score: 0.7235, Validation F1-score: 0.7405\n",
            "Epoch [10/10], Loss: 0.0561, Training F1-score: 0.7277, Validation F1-score: 0.7397\n",
            "Best validation score for iterations #5: 0.7465635738831615\n",
            "new config\n",
            "{'hidden_size': 305, 'lr': 0.06014059250433047, 'l2': 0.0002974906400645639, 'nonlin': 'relu', 'dropout': 0.9, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.2}\n",
            "Epoch [1/10], Loss: 0.4847, Training F1-score: 0.6521, Validation F1-score: 0.6555\n",
            "Epoch [2/10], Loss: 0.5037, Training F1-score: 0.6624, Validation F1-score: 0.6727\n",
            "Epoch [3/10], Loss: 1.3124, Training F1-score: 0.6861, Validation F1-score: 0.7010\n",
            "Epoch [4/10], Loss: 0.7719, Training F1-score: 0.6690, Validation F1-score: 0.6847\n",
            "Epoch [5/10], Loss: 0.9438, Training F1-score: 0.5528, Validation F1-score: 0.5232\n",
            "Epoch [6/10], Loss: 0.8460, Training F1-score: 0.6880, Validation F1-score: 0.7053\n",
            "Epoch [7/10], Loss: 0.5936, Training F1-score: 0.6649, Validation F1-score: 0.6744\n",
            "Epoch [8/10], Loss: 0.9684, Training F1-score: 0.6869, Validation F1-score: 0.6847\n",
            "Epoch [9/10], Loss: 0.5275, Training F1-score: 0.6635, Validation F1-score: 0.6744\n",
            "Epoch [10/10], Loss: 0.8036, Training F1-score: 0.6631, Validation F1-score: 0.6615\n",
            "Best validation score for iterations #6: 0.7053264604810997\n",
            "new config\n",
            "{'hidden_size': 335, 'lr': 0.013459274609456149, 'l2': 0.0003745825448490559, 'nonlin': 'relu', 'dropout': 0.8, 'num_layers': 2, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.8}\n",
            "Epoch [1/10], Loss: 0.1482, Training F1-score: 0.6696, Validation F1-score: 0.6658\n",
            "Epoch [2/10], Loss: 0.1268, Training F1-score: 0.6778, Validation F1-score: 0.6658\n",
            "Epoch [3/10], Loss: 0.3103, Training F1-score: 0.6885, Validation F1-score: 0.6890\n",
            "Epoch [4/10], Loss: 0.2303, Training F1-score: 0.6933, Validation F1-score: 0.6942\n",
            "Epoch [5/10], Loss: 0.1648, Training F1-score: 0.6789, Validation F1-score: 0.6753\n",
            "Epoch [6/10], Loss: 0.2494, Training F1-score: 0.6924, Validation F1-score: 0.6959\n",
            "Epoch [7/10], Loss: 0.1342, Training F1-score: 0.6760, Validation F1-score: 0.6701\n",
            "Epoch [8/10], Loss: 0.2380, Training F1-score: 0.6940, Validation F1-score: 0.7036\n",
            "Epoch [9/10], Loss: 0.1265, Training F1-score: 0.6826, Validation F1-score: 0.6778\n",
            "Epoch [10/10], Loss: 0.1998, Training F1-score: 0.6651, Validation F1-score: 0.6684\n",
            "Best validation score for iterations #7: 0.7036082474226805\n",
            "new config\n",
            "{'hidden_size': 196, 'lr': 0.06653248519921326, 'l2': 0.00017234394424133355, 'nonlin': 'tanh', 'dropout': 0.1, 'num_layers': 2, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.5}\n",
            "Epoch [1/10], Loss: 0.4791, Training F1-score: 0.6802, Validation F1-score: 0.6993\n",
            "Epoch [2/10], Loss: 1.0471, Training F1-score: 0.6834, Validation F1-score: 0.7010\n",
            "Epoch [3/10], Loss: 0.7265, Training F1-score: 0.3336, Validation F1-score: 0.3136\n",
            "Epoch [4/10], Loss: 0.7900, Training F1-score: 0.6397, Validation F1-score: 0.6280\n",
            "Epoch [5/10], Loss: 1.3561, Training F1-score: 0.6589, Validation F1-score: 0.6478\n",
            "Epoch [6/10], Loss: 1.0372, Training F1-score: 0.6859, Validation F1-score: 0.7053\n",
            "Epoch [7/10], Loss: 0.5813, Training F1-score: 0.6541, Validation F1-score: 0.6615\n",
            "Epoch [8/10], Loss: 1.0961, Training F1-score: 0.6204, Validation F1-score: 0.6074\n",
            "Epoch [9/10], Loss: 0.6519, Training F1-score: 0.6734, Validation F1-score: 0.6821\n",
            "Epoch [10/10], Loss: 0.9494, Training F1-score: 0.6765, Validation F1-score: 0.6916\n",
            "Best validation score for iterations #8: 0.7053264604810997\n",
            "new config\n",
            "{'hidden_size': 239, 'lr': 0.03225706256644881, 'l2': 0.004644630978559347, 'nonlin': 'relu', 'dropout': 0.1, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.9}\n",
            "Epoch [1/10], Loss: 0.3008, Training F1-score: 0.6811, Validation F1-score: 0.6993\n",
            "Epoch [2/10], Loss: 0.1791, Training F1-score: 0.6499, Validation F1-score: 0.6375\n",
            "Epoch [3/10], Loss: 0.3694, Training F1-score: 0.6618, Validation F1-score: 0.6744\n",
            "Epoch [4/10], Loss: 0.7924, Training F1-score: 0.6891, Validation F1-score: 0.7088\n",
            "Epoch [5/10], Loss: 0.5726, Training F1-score: 0.6898, Validation F1-score: 0.7079\n",
            "Epoch [6/10], Loss: 0.3872, Training F1-score: 0.6718, Validation F1-score: 0.6675\n",
            "Epoch [7/10], Loss: 0.5967, Training F1-score: 0.6878, Validation F1-score: 0.7088\n",
            "Epoch [8/10], Loss: 0.2980, Training F1-score: 0.6684, Validation F1-score: 0.6821\n",
            "Epoch [9/10], Loss: 0.3705, Training F1-score: 0.6001, Validation F1-score: 0.5627\n",
            "Epoch [10/10], Loss: 0.5761, Training F1-score: 0.6852, Validation F1-score: 0.6976\n",
            "Best validation score for iterations #9: 0.7087628865979382\n",
            "new config\n",
            "{'hidden_size': 156, 'lr': 0.08431476024672065, 'l2': 0.0001915898118438096, 'nonlin': 'relu', 'dropout': 0.6, 'num_layers': 1, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.6}\n",
            "Epoch [1/10], Loss: 0.8683, Training F1-score: 0.6482, Validation F1-score: 0.6598\n",
            "Epoch [2/10], Loss: 1.5662, Training F1-score: 0.6811, Validation F1-score: 0.6727\n",
            "Epoch [3/10], Loss: 1.3349, Training F1-score: 0.6973, Validation F1-score: 0.6873\n",
            "Epoch [4/10], Loss: 0.8999, Training F1-score: 0.7066, Validation F1-score: 0.7079\n",
            "Epoch [5/10], Loss: 0.9029, Training F1-score: 0.6867, Validation F1-score: 0.6761\n",
            "Epoch [6/10], Loss: 0.9285, Training F1-score: 0.6548, Validation F1-score: 0.6624\n",
            "Epoch [7/10], Loss: 0.8413, Training F1-score: 0.6655, Validation F1-score: 0.6718\n",
            "Epoch [8/10], Loss: 0.8572, Training F1-score: 0.6666, Validation F1-score: 0.6546\n",
            "Epoch [9/10], Loss: 0.8143, Training F1-score: 0.6578, Validation F1-score: 0.6564\n",
            "Epoch [10/10], Loss: 1.0805, Training F1-score: 0.6718, Validation F1-score: 0.6503\n",
            "Best validation score for iterations #10: 0.7079037800687286\n",
            "new config\n",
            "{'hidden_size': 391, 'lr': 0.0014923461011980752, 'l2': 0.0011081559309919131, 'nonlin': 'relu', 'dropout': 0.9, 'num_layers': 1, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.9}\n",
            "Epoch [1/10], Loss: 0.0386, Training F1-score: 0.7320, Validation F1-score: 0.7448\n",
            "Epoch [2/10], Loss: 0.0476, Training F1-score: 0.7504, Validation F1-score: 0.7491\n",
            "Epoch [3/10], Loss: 0.0352, Training F1-score: 0.7550, Validation F1-score: 0.7655\n",
            "Epoch [4/10], Loss: 0.0398, Training F1-score: 0.7723, Validation F1-score: 0.7620\n",
            "Epoch [5/10], Loss: 0.0331, Training F1-score: 0.7660, Validation F1-score: 0.7663\n",
            "Epoch [6/10], Loss: 0.0327, Training F1-score: 0.7662, Validation F1-score: 0.7526\n",
            "Epoch [7/10], Loss: 0.0437, Training F1-score: 0.7818, Validation F1-score: 0.7732\n",
            "Epoch [8/10], Loss: 0.0281, Training F1-score: 0.7802, Validation F1-score: 0.7689\n",
            "Epoch [9/10], Loss: 0.0339, Training F1-score: 0.7855, Validation F1-score: 0.7663\n",
            "Epoch [10/10], Loss: 0.0323, Training F1-score: 0.7951, Validation F1-score: 0.7741\n",
            "Best validation score for iterations #11: 0.7740549828178694\n",
            "new config\n",
            "{'hidden_size': 203, 'lr': 0.0013801468767845337, 'l2': 0.0013527798493541594, 'nonlin': 'relu', 'dropout': 0.6, 'num_layers': 2, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.7000000000000001}\n",
            "Epoch [1/10], Loss: 0.0329, Training F1-score: 0.7279, Validation F1-score: 0.7405\n",
            "Epoch [2/10], Loss: 0.0434, Training F1-score: 0.7625, Validation F1-score: 0.7612\n",
            "Epoch [3/10], Loss: 0.0363, Training F1-score: 0.7531, Validation F1-score: 0.7491\n",
            "Epoch [4/10], Loss: 0.0324, Training F1-score: 0.7609, Validation F1-score: 0.7560\n",
            "Epoch [5/10], Loss: 0.0390, Training F1-score: 0.7760, Validation F1-score: 0.7672\n",
            "Epoch [6/10], Loss: 0.0338, Training F1-score: 0.7684, Validation F1-score: 0.7612\n",
            "Epoch [7/10], Loss: 0.0287, Training F1-score: 0.7793, Validation F1-score: 0.7646\n",
            "Epoch [8/10], Loss: 0.0363, Training F1-score: 0.7899, Validation F1-score: 0.7680\n",
            "Epoch [9/10], Loss: 0.0276, Training F1-score: 0.7787, Validation F1-score: 0.7637\n",
            "Epoch [10/10], Loss: 0.0317, Training F1-score: 0.7892, Validation F1-score: 0.7689\n",
            "Best validation score for iterations #12: 0.7689003436426117\n",
            "new config\n",
            "{'hidden_size': 445, 'lr': 0.0777919269872273, 'l2': 0.00027916493871627115, 'nonlin': 'tanh', 'dropout': 0.9, 'num_layers': 1, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.30000000000000004}\n",
            "Epoch [1/10], Loss: 0.8353, Training F1-score: 0.6626, Validation F1-score: 0.6641\n",
            "Epoch [2/10], Loss: 1.4376, Training F1-score: 0.6935, Validation F1-score: 0.7105\n",
            "Epoch [3/10], Loss: 0.9940, Training F1-score: 0.6819, Validation F1-score: 0.6985\n",
            "Epoch [4/10], Loss: 1.1429, Training F1-score: 0.6887, Validation F1-score: 0.7027\n",
            "Epoch [5/10], Loss: 0.6694, Training F1-score: 0.6753, Validation F1-score: 0.6813\n",
            "Epoch [6/10], Loss: 1.2927, Training F1-score: 0.6784, Validation F1-score: 0.7027\n",
            "Epoch [7/10], Loss: 0.7193, Training F1-score: 0.6598, Validation F1-score: 0.6692\n",
            "Epoch [8/10], Loss: 1.2413, Training F1-score: 0.6657, Validation F1-score: 0.6744\n",
            "Epoch [9/10], Loss: 1.0035, Training F1-score: 0.6767, Validation F1-score: 0.6959\n",
            "Epoch [10/10], Loss: 0.5504, Training F1-score: 0.6826, Validation F1-score: 0.6916\n",
            "Best validation score for iterations #13: 0.7104810996563574\n",
            "new config\n",
            "{'hidden_size': 164, 'lr': 0.015742241703861116, 'l2': 0.0003192289778893747, 'nonlin': 'tanh', 'dropout': 0.6, 'num_layers': 2, 'mode': 0, 'optimizer': 'Adam', 'momentum': 0.5}\n",
            "Epoch [1/10], Loss: 0.1554, Training F1-score: 0.6920, Validation F1-score: 0.6950\n",
            "Epoch [2/10], Loss: 0.0930, Training F1-score: 0.7025, Validation F1-score: 0.7096\n",
            "Epoch [3/10], Loss: 0.2758, Training F1-score: 0.6962, Validation F1-score: 0.7070\n",
            "Epoch [4/10], Loss: 0.2320, Training F1-score: 0.7332, Validation F1-score: 0.7277\n",
            "Epoch [5/10], Loss: 0.3713, Training F1-score: 0.7491, Validation F1-score: 0.7517\n",
            "Epoch [6/10], Loss: 0.1779, Training F1-score: 0.7487, Validation F1-score: 0.7414\n",
            "Epoch [7/10], Loss: 0.2852, Training F1-score: 0.7594, Validation F1-score: 0.7620\n",
            "Epoch [8/10], Loss: 0.1135, Training F1-score: 0.7513, Validation F1-score: 0.7509\n",
            "Epoch [9/10], Loss: 0.0701, Training F1-score: 0.7725, Validation F1-score: 0.7663\n",
            "Epoch [10/10], Loss: 0.0651, Training F1-score: 0.7714, Validation F1-score: 0.7577\n",
            "Best validation score for iterations #14: 0.7663230240549829\n",
            "new config\n",
            "{'hidden_size': 467, 'lr': 0.0005390398259830882, 'l2': 0.005982593492257212, 'nonlin': 'relu', 'dropout': 0.4, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.7000000000000001}\n",
            "Epoch [1/10], Loss: 0.0374, Training F1-score: 0.6922, Validation F1-score: 0.7225\n",
            "Epoch [2/10], Loss: 0.0357, Training F1-score: 0.7082, Validation F1-score: 0.7345\n",
            "Epoch [3/10], Loss: 0.0338, Training F1-score: 0.7152, Validation F1-score: 0.7423\n",
            "Epoch [4/10], Loss: 0.0322, Training F1-score: 0.7191, Validation F1-score: 0.7363\n",
            "Epoch [5/10], Loss: 0.0312, Training F1-score: 0.7220, Validation F1-score: 0.7388\n",
            "Epoch [6/10], Loss: 0.0289, Training F1-score: 0.7296, Validation F1-score: 0.7526\n",
            "Epoch [7/10], Loss: 0.0287, Training F1-score: 0.7290, Validation F1-score: 0.7474\n",
            "Epoch [8/10], Loss: 0.0271, Training F1-score: 0.7255, Validation F1-score: 0.7388\n",
            "Epoch [9/10], Loss: 0.0298, Training F1-score: 0.7272, Validation F1-score: 0.7457\n",
            "Epoch [10/10], Loss: 0.0277, Training F1-score: 0.7272, Validation F1-score: 0.7440\n",
            "Best validation score for iterations #15: 0.752577319587629\n",
            "new config\n",
            "{'hidden_size': 454, 'lr': 0.004687359681187115, 'l2': 0.008123583697315773, 'nonlin': 'tanh', 'dropout': 0.30000000000000004, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.1}\n",
            "Epoch [1/10], Loss: 0.0643, Training F1-score: 0.6837, Validation F1-score: 0.6899\n",
            "Epoch [2/10], Loss: 0.1035, Training F1-score: 0.7104, Validation F1-score: 0.7156\n",
            "Epoch [3/10], Loss: 0.0889, Training F1-score: 0.7130, Validation F1-score: 0.7216\n",
            "Epoch [4/10], Loss: 0.0774, Training F1-score: 0.7075, Validation F1-score: 0.7139\n",
            "Epoch [5/10], Loss: 0.0580, Training F1-score: 0.7034, Validation F1-score: 0.7053\n",
            "Epoch [6/10], Loss: 0.0936, Training F1-score: 0.7194, Validation F1-score: 0.7311\n",
            "Epoch [7/10], Loss: 0.0632, Training F1-score: 0.7082, Validation F1-score: 0.7199\n",
            "Epoch [8/10], Loss: 0.0893, Training F1-score: 0.7093, Validation F1-score: 0.7311\n",
            "Epoch [9/10], Loss: 0.0754, Training F1-score: 0.7170, Validation F1-score: 0.7388\n",
            "Epoch [10/10], Loss: 0.0519, Training F1-score: 0.7089, Validation F1-score: 0.7294\n",
            "Best validation score for iterations #16: 0.738831615120275\n",
            "new config\n",
            "{'hidden_size': 386, 'lr': 0.0003649908559630398, 'l2': 1.2449680238414656e-05, 'nonlin': 'tanh', 'dropout': 0.1, 'num_layers': 2, 'mode': 2, 'optimizer': 'Adam', 'momentum': 0.2}\n",
            "Epoch [1/10], Loss: 0.0298, Training F1-score: 0.7483, Validation F1-score: 0.7517\n",
            "Epoch [2/10], Loss: 0.0239, Training F1-score: 0.7710, Validation F1-score: 0.7749\n",
            "Epoch [3/10], Loss: 0.0218, Training F1-score: 0.7756, Validation F1-score: 0.7655\n",
            "Epoch [4/10], Loss: 0.0203, Training F1-score: 0.7925, Validation F1-score: 0.7792\n",
            "Epoch [5/10], Loss: 0.0175, Training F1-score: 0.7936, Validation F1-score: 0.7698\n",
            "Epoch [6/10], Loss: 0.0169, Training F1-score: 0.7992, Validation F1-score: 0.7680\n",
            "Epoch [7/10], Loss: 0.0165, Training F1-score: 0.8021, Validation F1-score: 0.7646\n",
            "Epoch [8/10], Loss: 0.0161, Training F1-score: 0.8069, Validation F1-score: 0.7560\n",
            "Epoch [9/10], Loss: 0.0232, Training F1-score: 0.8124, Validation F1-score: 0.7440\n",
            "Epoch [10/10], Loss: 0.0246, Training F1-score: 0.7885, Validation F1-score: 0.7405\n",
            "Best validation score for iterations #17: 0.7792096219931272\n",
            "new config\n",
            "{'hidden_size': 117, 'lr': 0.00012619409055322133, 'l2': 7.677205405402668e-05, 'nonlin': 'tanh', 'dropout': 0.1, 'num_layers': 1, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.30000000000000004}\n",
            "Epoch [1/10], Loss: 0.0411, Training F1-score: 0.6701, Validation F1-score: 0.6847\n",
            "Epoch [2/10], Loss: 0.0296, Training F1-score: 0.6764, Validation F1-score: 0.6924\n",
            "Epoch [3/10], Loss: 0.0280, Training F1-score: 0.6835, Validation F1-score: 0.6942\n",
            "Epoch [4/10], Loss: 0.0268, Training F1-score: 0.6961, Validation F1-score: 0.7191\n",
            "Epoch [5/10], Loss: 0.0256, Training F1-score: 0.7323, Validation F1-score: 0.7543\n",
            "Epoch [6/10], Loss: 0.0233, Training F1-score: 0.7448, Validation F1-score: 0.7543\n",
            "Epoch [7/10], Loss: 0.0225, Training F1-score: 0.7408, Validation F1-score: 0.7543\n",
            "Epoch [8/10], Loss: 0.0219, Training F1-score: 0.7537, Validation F1-score: 0.7663\n",
            "Epoch [9/10], Loss: 0.0221, Training F1-score: 0.7629, Validation F1-score: 0.7706\n",
            "Epoch [10/10], Loss: 0.0210, Training F1-score: 0.7664, Validation F1-score: 0.7680\n",
            "Best validation score for iterations #18: 0.770618556701031\n",
            "new config\n",
            "{'hidden_size': 221, 'lr': 0.00445959979936001, 'l2': 0.0025089621497357876, 'nonlin': 'tanh', 'dropout': 0.2, 'num_layers': 2, 'mode': 1, 'optimizer': 'Adam', 'momentum': 0.4}\n",
            "Epoch [1/10], Loss: 0.0493, Training F1-score: 0.7207, Validation F1-score: 0.7234\n",
            "Epoch [2/10], Loss: 0.0914, Training F1-score: 0.7541, Validation F1-score: 0.7586\n",
            "Epoch [3/10], Loss: 0.0308, Training F1-score: 0.6600, Validation F1-score: 0.6486\n",
            "Epoch [4/10], Loss: 0.1043, Training F1-score: 0.7677, Validation F1-score: 0.7620\n",
            "Epoch [5/10], Loss: 0.1082, Training F1-score: 0.7769, Validation F1-score: 0.7672\n",
            "Epoch [6/10], Loss: 0.0521, Training F1-score: 0.7717, Validation F1-score: 0.7552\n",
            "Epoch [7/10], Loss: 0.0849, Training F1-score: 0.7715, Validation F1-score: 0.7517\n",
            "Epoch [8/10], Loss: 0.0790, Training F1-score: 0.7754, Validation F1-score: 0.7509\n",
            "Epoch [9/10], Loss: 0.0573, Training F1-score: 0.7756, Validation F1-score: 0.7569\n",
            "Epoch [10/10], Loss: 0.0590, Training F1-score: 0.7784, Validation F1-score: 0.7371\n",
            "Best validation score for iterations #19: 0.7671821305841925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIl_f4DsLFzl",
        "outputId": "af278cc6-52da-46ff-affc-da232b5eb206"
      },
      "source": [
        "MAX_EPOCHS = 20\n",
        "best_config = {'hidden_size': 302, \n",
        "               'lr': 0.00010769630091763721, \n",
        "               'l2': 2.5888680371842294e-05, \n",
        "               'nonlin': 'tanh', \n",
        "               'dropout': 0.1, \n",
        "               'num_layers': 2, \n",
        "               'mode': 0, \n",
        "               'optimizer': 'Adam', \n",
        "               'momentum': 0.1\n",
        "               }\n",
        "\n",
        "best_model = SeqModel(embedding_size=EMBEDDING_SIZE, \n",
        "                  vocab_size=VOCAB_SIZE, \n",
        "                  output_size=NUM_CLASSES, \n",
        "                  hidden_size=best_config[\"hidden_size\"], \n",
        "                  num_layers=best_config[\"num_layers\"], \n",
        "                  nonlin=best_config[\"nonlin\"],\n",
        "                  dropout_rate=best_config[\"dropout\"],\n",
        "                  mode=best_config[\"mode\"],\n",
        "                  unit=\"gru\",\n",
        "                  more_features=False)\n",
        "best_model = best_model.to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "if best_config[\"optimizer\"] == \"Adam\":\n",
        "  optimizer = torch.optim.Adam(best_model.parameters(), lr=best_config[\"lr\"], weight_decay=best_config[\"l2\"])\n",
        "else:\n",
        "  optimizer = torch.optim.Adam(best_model.parameters(), lr=best_config[\"lr\"], weight_decay=best_config[\"l2\"])\n",
        "\n",
        "\n",
        "max_val = 0\n",
        "best_epoch = 0\n",
        "for epoch in range(MAX_EPOCHS):\n",
        "    # train the model for one pass over the data\n",
        "    train_loss = train(train_iter, best_model, criterion, optimizer, device)  \n",
        "    # compute the training accuracy\n",
        "    train_acc, train_f1 = evaluate(train_iter, best_model, criterion, device)\n",
        "    # compute the validation accuracy\n",
        "    vac_acc, val_f1 = evaluate(val_iter, best_model, criterion, device)\n",
        "    if val_f1 > max_val:\n",
        "        max_val = val_f1\n",
        "        best_epoch = epoch + 1\n",
        "    # print the loss for every epoch\n",
        "    print('Epoch [{}/{}], Loss: {:.4f}, Training F1-score: {:.4f}, Validation F1-score: {:.4f}'.format(epoch+1, MAX_EPOCHS, train_loss, train_f1, val_f1))\n",
        "\n",
        "print(\"Best validation score for iterations #{}: {}\".format(i,max_val))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.0256, Training F1-score: 0.6966, Validation F1-score: 0.7088\n",
            "Epoch [2/20], Loss: 0.0210, Training F1-score: 0.7515, Validation F1-score: 0.7715\n",
            "Epoch [3/20], Loss: 0.0192, Training F1-score: 0.7651, Validation F1-score: 0.7784\n",
            "Epoch [4/20], Loss: 0.0186, Training F1-score: 0.7714, Validation F1-score: 0.7861\n",
            "Epoch [5/20], Loss: 0.0182, Training F1-score: 0.7771, Validation F1-score: 0.7861\n",
            "Epoch [6/20], Loss: 0.0178, Training F1-score: 0.7830, Validation F1-score: 0.7852\n",
            "Epoch [7/20], Loss: 0.0175, Training F1-score: 0.7852, Validation F1-score: 0.7835\n",
            "Epoch [8/20], Loss: 0.0173, Training F1-score: 0.7909, Validation F1-score: 0.7852\n",
            "Epoch [9/20], Loss: 0.0170, Training F1-score: 0.7949, Validation F1-score: 0.7809\n",
            "Epoch [10/20], Loss: 0.0168, Training F1-score: 0.8006, Validation F1-score: 0.7818\n",
            "Epoch [11/20], Loss: 0.0165, Training F1-score: 0.8017, Validation F1-score: 0.7835\n",
            "Epoch [12/20], Loss: 0.0163, Training F1-score: 0.8041, Validation F1-score: 0.7784\n",
            "Epoch [13/20], Loss: 0.0161, Training F1-score: 0.8076, Validation F1-score: 0.7801\n",
            "Epoch [14/20], Loss: 0.0158, Training F1-score: 0.8131, Validation F1-score: 0.7784\n",
            "Epoch [15/20], Loss: 0.0155, Training F1-score: 0.8154, Validation F1-score: 0.7741\n",
            "Epoch [16/20], Loss: 0.0153, Training F1-score: 0.8177, Validation F1-score: 0.7732\n",
            "Epoch [17/20], Loss: 0.0150, Training F1-score: 0.8233, Validation F1-score: 0.7698\n",
            "Epoch [18/20], Loss: 0.0147, Training F1-score: 0.8249, Validation F1-score: 0.7680\n",
            "Epoch [19/20], Loss: 0.0144, Training F1-score: 0.8271, Validation F1-score: 0.7612\n",
            "Epoch [20/20], Loss: 0.0141, Training F1-score: 0.8321, Validation F1-score: 0.7569\n",
            "Best validation score for iterations #2041: 0.7860824742268041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moDt95wbMYE1"
      },
      "source": [
        "torch.save(best_model.state_dict,\"./model_deploy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plSsPCRZeAFt"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}